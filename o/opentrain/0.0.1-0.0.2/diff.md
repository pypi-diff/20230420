# Comparing `tmp/opentrain-0.0.1.tar.gz` & `tmp/opentrain-0.0.2.tar.gz`

## Comparing `opentrain-0.0.1.tar` & `opentrain-0.0.2.tar`

### file list

```diff
@@ -1,8 +1,10 @@
--rw-r--r--   0        0        0     1297 2020-02-02 00:00:00.000000 opentrain-0.0.1/mkdocs.yml
--rw-r--r--   0        0        0      182 2020-02-02 00:00:00.000000 opentrain-0.0.1/src/opentrain/__init__.py
--rw-r--r--   0        0        0     1482 2020-02-02 00:00:00.000000 opentrain-0.0.1/src/opentrain/train.py
--rw-r--r--   0        0        0     1316 2020-02-02 00:00:00.000000 opentrain-0.0.1/.gitignore
--rw-r--r--   0        0        0     1104 2020-02-02 00:00:00.000000 opentrain-0.0.1/LICENSE
--rw-r--r--   0        0        0      748 2020-02-02 00:00:00.000000 opentrain-0.0.1/README.md
--rw-r--r--   0        0        0     2486 2020-02-02 00:00:00.000000 opentrain-0.0.1/pyproject.toml
--rw-r--r--   0        0        0     2232 2020-02-02 00:00:00.000000 opentrain-0.0.1/PKG-INFO
+-rw-r--r--   0        0        0     1297 2020-02-02 00:00:00.000000 opentrain-0.0.2/mkdocs.yml
+-rw-r--r--   0        0        0      182 2020-02-02 00:00:00.000000 opentrain-0.0.2/src/opentrain/__init__.py
+-rw-r--r--   0        0        0     1120 2020-02-02 00:00:00.000000 opentrain-0.0.2/src/opentrain/predict.py
+-rw-r--r--   0        0        0     2277 2020-02-02 00:00:00.000000 opentrain-0.0.2/src/opentrain/train.py
+-rw-r--r--   0        0        0      405 2020-02-02 00:00:00.000000 opentrain-0.0.2/src/opentrain/utils.py
+-rw-r--r--   0        0        0     1316 2020-02-02 00:00:00.000000 opentrain-0.0.2/.gitignore
+-rw-r--r--   0        0        0     1104 2020-02-02 00:00:00.000000 opentrain-0.0.2/LICENSE
+-rw-r--r--   0        0        0     1583 2020-02-02 00:00:00.000000 opentrain-0.0.2/README.md
+-rw-r--r--   0        0        0     2479 2020-02-02 00:00:00.000000 opentrain-0.0.2/pyproject.toml
+-rw-r--r--   0        0        0     3067 2020-02-02 00:00:00.000000 opentrain-0.0.2/PKG-INFO
```

### Comparing `opentrain-0.0.1/mkdocs.yml` & `opentrain-0.0.2/mkdocs.yml`

 * *Files identical despite different names*

### Comparing `opentrain-0.0.1/src/opentrain/train.py` & `opentrain-0.0.2/src/opentrain/train.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,31 @@
 import json
-import sys
+import warnings
 from pathlib import Path
 from typing import Union
 
 import openai
 
 
 class OpenAITrainer:
     def __init__(self, model: str = "ada") -> None:
+        assert model in [
+            "ada",
+            "babbage",
+            "curie",
+            "davinci",
+        ], "The model must be one of the following: ada, babbage, curie, davinci."
         self.model = model
 
     def train(
         self,
         path_or_buf: Union[str, Path, list],
         epochs: int = 10,
         batch_size: int = 32,
-    ) -> dict:
+    ) -> str:
         if isinstance(path_or_buf, list):
             file_path = self._prepare_training_data(path_or_buf)
         elif isinstance(path_or_buf, Path):
             file_path = path_or_buf.as_posix()
         else:
             file_path = path_or_buf
 
@@ -31,17 +37,29 @@
         fine_tune_response = openai.FineTune.create(
             training_file=file_id,
             model=self.model,
             n_epochs=epochs,
             batch_size=batch_size,
         )
         self.fine_tune_id = fine_tune_response.id
-        for event in openai.FineTune.stream_events(id=self.fine_tune_id):
-            sys.stdout.write(f"\r{event['event']}")
-        return openai.FineTune.retrieve(id=self.fine_tune_id).fine_tuned_model
+        warnings.warn(
+            "Since the OpenAI API may take from minutes to hours depending on the size"
+            " of the training data, then from now on, you'll be able to check its"
+            " progress via the following command: `openai api fine_tunes.follow -i"
+            f" {self.fine_tune_id}`. Once the training is completed, then you'll be"
+            " able to use `OpenAIPredict` with the either the fine tune id returned,"
+            " or from the model name generated by OpenAI linked to your account.",
+            stacklevel=2,
+        )
+        return self.fine_tune_id
+
+    def track_training(self) -> str:
+        if not self.fine_tune_id:
+            raise ValueError("You must first train the model.")
+        return openai.FineTune.stream_events(self.fine_tune_id)
 
     def _prepare_training_data(self, buf: list) -> str:
         file_path = Path.cwd() / "training_data.jsonl"
         with open(file_path, "w") as f:
             for entry in buf:
                 json.dump(entry, f)
                 f.write("\n")
```

### Comparing `opentrain-0.0.1/.gitignore` & `opentrain-0.0.2/.gitignore`

 * *Files identical despite different names*

### Comparing `opentrain-0.0.1/LICENSE` & `opentrain-0.0.2/LICENSE`

 * *Files identical despite different names*

### Comparing `opentrain-0.0.1/pyproject.toml` & `opentrain-0.0.2/pyproject.toml`

 * *Files 0% similar despite different names*

```diff
@@ -86,15 +86,15 @@
   "tests",
 ]
 
 [tool.hatch.envs.test.scripts]
 run = "pytest tests/ --durations 0 -s"
 
 [[tool.hatch.envs.test.matrix]]
-python = ["38", "39", "310", "311"]
+python = ["38", "39", "310"]
 
 [tool.hatch.envs.docs]
 features = [
   "docs",
 ]
 
 [tool.hatch.envs.docs.scripts]
```

### Comparing `opentrain-0.0.1/PKG-INFO` & `opentrain-0.0.2/PKG-INFO`

 * *Files 22% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: opentrain
-Version: 0.0.1
+Version: 0.0.2
 Summary: üöÇ Fine-tune OpenAI models for text classification, question answering, and more
 Project-URL: Documentation, https://alvarobartt.github.io/opentrain
 Project-URL: Issues, https://github.com/alvarobartt/opentrain/issues
 Project-URL: Source, https://github.com/alvarobartt/opentrain
 Author-email: Alvaro Bartolome <alvarobartt@gmail.com>
 License-Expression: MIT
 License-File: LICENSE
@@ -38,27 +38,44 @@
   </p>
 </div>
 
 ---
 
 `opentrain` is a simple Python package to fine-tune OpenAI models for task-specific purposes such as text classification, token classification, or question answering.
 
-## Usage
+## üíª Usage
+
+### ü¶æ Fine-tune
 
 ```python
 import openai
 from opentrain.train import OpenAITrainer
+
 openai.api_key = "<ADD_OPENAI_API_KEY_HERE>"
+
 trainer = OpenAITrainer(model="ada")
 trainer.train(
     [
         {
             "prompt": "I love to play soccer ->",
             "completion": " soccer",
         },
         {
             "prompt": "I love to play basketball ->",
             "completion": " basketball",
         },
     ],
 )
 ```
+
+## ‚ö†Ô∏è Warning
+
+Fine-tuning OpenAI models via their API may take too long, so please be patient. Also, bear in mind
+that in some cases you just won't need to fine-tune an OpenAI model for your task.
+
+To keep track of all the models you fine-tuned, you should visit https://platform.openai.com/account/usage, 
+and then in the "Daily usage breakdown (UTC)" you'll need to select the date where you triggered the
+fine-tuning and click on "Fine-tune training" to see all the fine-tune training requests that you sent.
+
+Besides that, in the OpenAI Playground at https://platform.openai.com/playground, you'll see a dropdown
+menu for all the available models, both the default ones and the ones you fine-tuned. Usually, in the 
+following format `<MODEL>:ft-personal-<DATE>`, e.g. `ada:ft-personal-2021-03-01`.
```

