# Comparing `tmp/deepview_validator-3.0.2-py3-none-any.whl.zip` & `tmp/deepview_validator-3.0.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,45 +1,46 @@
-Zip file size: 96436 bytes, number of entries: 43
--rw-rw-r--  2.0 unx      760 b- defN 23-Apr-18 20:21 deepview/validator/__init__.py
--rw-rw-r--  2.0 unx    15665 b- defN 23-Apr-18 20:21 deepview/validator/__main__.py
--rw-rw-r--  2.0 unx    12847 b- defN 23-Apr-18 20:21 deepview/validator/exceptions.py
--rw-rw-r--  2.0 unx      497 b- defN 23-Apr-18 20:21 deepview/validator/datasets/__init__.py
--rw-rw-r--  2.0 unx    31118 b- defN 23-Apr-18 20:21 deepview/validator/datasets/core.py
--rw-rw-r--  2.0 unx    14296 b- defN 23-Apr-18 20:21 deepview/validator/datasets/darknet.py
--rw-rw-r--  2.0 unx     6820 b- defN 23-Apr-18 20:21 deepview/validator/datasets/tfrecord.py
--rw-rw-r--  2.0 unx      530 b- defN 23-Apr-18 20:21 deepview/validator/evaluators/__init__.py
--rw-rw-r--  2.0 unx     5067 b- defN 23-Apr-18 20:21 deepview/validator/evaluators/core.py
--rw-rw-r--  2.0 unx    24515 b- defN 23-Apr-18 20:21 deepview/validator/evaluators/detectionevaluator.py
--rw-rw-r--  2.0 unx    18731 b- defN 23-Apr-18 20:21 deepview/validator/evaluators/segmentationevaluator.py
--rw-rw-r--  2.0 unx      830 b- defN 23-Apr-18 20:21 deepview/validator/metrics/__init__.py
--rw-rw-r--  2.0 unx    11297 b- defN 23-Apr-18 20:21 deepview/validator/metrics/core.py
--rw-rw-r--  2.0 unx    31668 b- defN 23-Apr-18 20:21 deepview/validator/metrics/detectiondata.py
--rw-rw-r--  2.0 unx    25023 b- defN 23-Apr-18 20:21 deepview/validator/metrics/detectionmetrics.py
--rw-rw-r--  2.0 unx     4548 b- defN 23-Apr-18 20:21 deepview/validator/metrics/detectionutils.py
--rw-rw-r--  2.0 unx    17211 b- defN 23-Apr-18 20:21 deepview/validator/metrics/segmentationdata.py
--rw-rw-r--  2.0 unx     6319 b- defN 23-Apr-18 20:21 deepview/validator/metrics/segmentationmetrics.py
--rw-rw-r--  2.0 unx    11704 b- defN 23-Apr-18 20:21 deepview/validator/metrics/segmentationutils.py
--rw-rw-r--  2.0 unx      674 b- defN 23-Apr-18 20:21 deepview/validator/runners/__init__.py
--rw-rw-r--  2.0 unx     5144 b- defN 23-Apr-18 20:21 deepview/validator/runners/core.py
--rw-rw-r--  2.0 unx    13596 b- defN 23-Apr-18 20:21 deepview/validator/runners/deepviewrt.py
--rw-rw-r--  2.0 unx    14335 b- defN 23-Apr-18 20:21 deepview/validator/runners/keras.py
--rw-rw-r--  2.0 unx     6147 b- defN 23-Apr-18 20:21 deepview/validator/runners/offline.py
--rw-rw-r--  2.0 unx    16285 b- defN 23-Apr-18 20:21 deepview/validator/runners/tensorrt.py
--rw-rw-r--  2.0 unx    15389 b- defN 23-Apr-18 20:21 deepview/validator/runners/tflite.py
--rw-rw-r--  2.0 unx      600 b- defN 23-Apr-18 20:21 deepview/validator/runners/modelclient/__init__.py
--rw-rw-r--  2.0 unx    29387 b- defN 23-Apr-18 20:21 deepview/validator/runners/modelclient/boxes.py
--rw-rw-r--  2.0 unx     3104 b- defN 23-Apr-18 20:21 deepview/validator/runners/modelclient/core.py
--rw-rw-r--  2.0 unx    11846 b- defN 23-Apr-18 20:21 deepview/validator/runners/modelclient/segmentation.py
--rw-rw-r--  2.0 unx      521 b- defN 23-Apr-18 20:21 deepview/validator/visualize/__init__.py
--rw-rw-r--  2.0 unx    11059 b- defN 23-Apr-18 20:21 deepview/validator/visualize/core.py
--rw-rw-r--  2.0 unx     7014 b- defN 23-Apr-18 20:21 deepview/validator/visualize/detectiondrawer.py
--rw-rw-r--  2.0 unx    14479 b- defN 23-Apr-18 20:21 deepview/validator/visualize/segmentationdrawer.py
--rw-rw-r--  2.0 unx      574 b- defN 23-Apr-18 20:21 deepview/validator/writers/__init__.py
--rw-rw-r--  2.0 unx     7611 b- defN 23-Apr-18 20:21 deepview/validator/writers/console.py
--rw-rw-r--  2.0 unx    19839 b- defN 23-Apr-18 20:21 deepview/validator/writers/core.py
--rw-rw-r--  2.0 unx     9065 b- defN 23-Apr-18 20:21 deepview/validator/writers/tensorboard.py
--rw-rw-r--  2.0 unx      433 b- defN 23-Apr-18 20:21 deepview_validator-3.0.2.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-18 20:21 deepview_validator-3.0.2.dist-info/WHEEL
--rw-rw-r--  2.0 unx       73 b- defN 23-Apr-18 20:21 deepview_validator-3.0.2.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx        9 b- defN 23-Apr-18 20:21 deepview_validator-3.0.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     4175 b- defN 23-Apr-18 20:21 deepview_validator-3.0.2.dist-info/RECORD
-43 files, 430897 bytes uncompressed, 89598 bytes compressed:  79.2%
+Zip file size: 97981 bytes, number of entries: 44
+-rw-rw-r--  2.0 unx      760 b- defN 23-Apr-20 18:46 deepview/validator/__init__.py
+-rw-rw-r--  2.0 unx    15914 b- defN 23-Apr-20 18:46 deepview/validator/__main__.py
+-rw-rw-r--  2.0 unx    12847 b- defN 23-Apr-20 18:46 deepview/validator/exceptions.py
+-rw-rw-r--  2.0 unx      497 b- defN 23-Apr-20 18:46 deepview/validator/datasets/__init__.py
+-rw-rw-r--  2.0 unx    29989 b- defN 23-Apr-20 18:46 deepview/validator/datasets/core.py
+-rw-rw-r--  2.0 unx    14505 b- defN 23-Apr-20 18:46 deepview/validator/datasets/darknet.py
+-rw-rw-r--  2.0 unx     7029 b- defN 23-Apr-20 18:46 deepview/validator/datasets/tfrecord.py
+-rw-rw-r--  2.0 unx     3786 b- defN 23-Apr-20 18:46 deepview/validator/datasets/utils.py
+-rw-rw-r--  2.0 unx      530 b- defN 23-Apr-20 18:46 deepview/validator/evaluators/__init__.py
+-rw-rw-r--  2.0 unx     5067 b- defN 23-Apr-20 18:46 deepview/validator/evaluators/core.py
+-rw-rw-r--  2.0 unx    24515 b- defN 23-Apr-20 18:46 deepview/validator/evaluators/detectionevaluator.py
+-rw-rw-r--  2.0 unx    18731 b- defN 23-Apr-20 18:46 deepview/validator/evaluators/segmentationevaluator.py
+-rw-rw-r--  2.0 unx      830 b- defN 23-Apr-20 18:46 deepview/validator/metrics/__init__.py
+-rw-rw-r--  2.0 unx    11297 b- defN 23-Apr-20 18:46 deepview/validator/metrics/core.py
+-rw-rw-r--  2.0 unx    31668 b- defN 23-Apr-20 18:46 deepview/validator/metrics/detectiondata.py
+-rw-rw-r--  2.0 unx    25023 b- defN 23-Apr-20 18:46 deepview/validator/metrics/detectionmetrics.py
+-rw-rw-r--  2.0 unx     4548 b- defN 23-Apr-20 18:46 deepview/validator/metrics/detectionutils.py
+-rw-rw-r--  2.0 unx    17211 b- defN 23-Apr-20 18:46 deepview/validator/metrics/segmentationdata.py
+-rw-rw-r--  2.0 unx     6319 b- defN 23-Apr-20 18:46 deepview/validator/metrics/segmentationmetrics.py
+-rw-rw-r--  2.0 unx    11704 b- defN 23-Apr-20 18:46 deepview/validator/metrics/segmentationutils.py
+-rw-rw-r--  2.0 unx      674 b- defN 23-Apr-20 18:46 deepview/validator/runners/__init__.py
+-rw-rw-r--  2.0 unx     5144 b- defN 23-Apr-20 18:46 deepview/validator/runners/core.py
+-rw-rw-r--  2.0 unx    13596 b- defN 23-Apr-20 18:46 deepview/validator/runners/deepviewrt.py
+-rw-rw-r--  2.0 unx    14335 b- defN 23-Apr-20 18:46 deepview/validator/runners/keras.py
+-rw-rw-r--  2.0 unx     6147 b- defN 23-Apr-20 18:46 deepview/validator/runners/offline.py
+-rw-rw-r--  2.0 unx    16285 b- defN 23-Apr-20 18:46 deepview/validator/runners/tensorrt.py
+-rw-rw-r--  2.0 unx    15389 b- defN 23-Apr-20 18:46 deepview/validator/runners/tflite.py
+-rw-rw-r--  2.0 unx      600 b- defN 23-Apr-20 18:46 deepview/validator/runners/modelclient/__init__.py
+-rw-rw-r--  2.0 unx    29387 b- defN 23-Apr-20 18:46 deepview/validator/runners/modelclient/boxes.py
+-rw-rw-r--  2.0 unx     3116 b- defN 23-Apr-20 18:46 deepview/validator/runners/modelclient/core.py
+-rw-rw-r--  2.0 unx    11846 b- defN 23-Apr-20 18:46 deepview/validator/runners/modelclient/segmentation.py
+-rw-rw-r--  2.0 unx      521 b- defN 23-Apr-20 18:46 deepview/validator/visualize/__init__.py
+-rw-rw-r--  2.0 unx    11059 b- defN 23-Apr-20 18:46 deepview/validator/visualize/core.py
+-rw-rw-r--  2.0 unx     7014 b- defN 23-Apr-20 18:46 deepview/validator/visualize/detectiondrawer.py
+-rw-rw-r--  2.0 unx    14479 b- defN 23-Apr-20 18:46 deepview/validator/visualize/segmentationdrawer.py
+-rw-rw-r--  2.0 unx      574 b- defN 23-Apr-20 18:46 deepview/validator/writers/__init__.py
+-rw-rw-r--  2.0 unx     7611 b- defN 23-Apr-20 18:46 deepview/validator/writers/console.py
+-rw-rw-r--  2.0 unx    19839 b- defN 23-Apr-20 18:46 deepview/validator/writers/core.py
+-rw-rw-r--  2.0 unx     9065 b- defN 23-Apr-20 18:46 deepview/validator/writers/tensorboard.py
+-rw-rw-r--  2.0 unx      433 b- defN 23-Apr-20 18:46 deepview_validator-3.0.3.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-20 18:46 deepview_validator-3.0.3.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       73 b- defN 23-Apr-20 18:46 deepview_validator-3.0.3.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx        9 b- defN 23-Apr-20 18:46 deepview_validator-3.0.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4268 b- defN 23-Apr-20 18:46 deepview_validator-3.0.3.dist-info/RECORD
+44 files, 434326 bytes uncompressed, 90995 bytes compressed:  79.0%
```

## zipnote {}

```diff
@@ -15,14 +15,17 @@
 
 Filename: deepview/validator/datasets/darknet.py
 Comment: 
 
 Filename: deepview/validator/datasets/tfrecord.py
 Comment: 
 
+Filename: deepview/validator/datasets/utils.py
+Comment: 
+
 Filename: deepview/validator/evaluators/__init__.py
 Comment: 
 
 Filename: deepview/validator/evaluators/core.py
 Comment: 
 
 Filename: deepview/validator/evaluators/detectionevaluator.py
@@ -108,23 +111,23 @@
 
 Filename: deepview/validator/writers/core.py
 Comment: 
 
 Filename: deepview/validator/writers/tensorboard.py
 Comment: 
 
-Filename: deepview_validator-3.0.2.dist-info/METADATA
+Filename: deepview_validator-3.0.3.dist-info/METADATA
 Comment: 
 
-Filename: deepview_validator-3.0.2.dist-info/WHEEL
+Filename: deepview_validator-3.0.3.dist-info/WHEEL
 Comment: 
 
-Filename: deepview_validator-3.0.2.dist-info/entry_points.txt
+Filename: deepview_validator-3.0.3.dist-info/entry_points.txt
 Comment: 
 
-Filename: deepview_validator-3.0.2.dist-info/top_level.txt
+Filename: deepview_validator-3.0.3.dist-info/top_level.txt
 Comment: 
 
-Filename: deepview_validator-3.0.2.dist-info/RECORD
+Filename: deepview_validator-3.0.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## deepview/validator/__main__.py

```diff
@@ -12,16 +12,17 @@
     SegmentationModelPack
 from deepview.validator.runners.modelclient import BoxesModelPack, BoxesYolo
 from deepview.validator.exceptions import UnsupportedModelExtensionException
 from deepview.validator.exceptions import UnsupportedValidationTypeException
 from deepview.validator.exceptions import UnsupportedApplicationException
 from deepview.validator.evaluators import DetectionEval, SegmentationEval
 from deepview.validator.exceptions import UnsupportedModelTypeException
-from deepview.validator.writers import Writer
+from deepview.validator.datasets.utils import instantiate_dataset
 from deepview.validator.datasets import Dataset
+from deepview.validator.writers import Writer
 from deepview.validator import version
 from os import path
 import argparse
 
 
 def main():
     parser = argparse.ArgumentParser(
@@ -223,22 +224,26 @@
         "nms": args.nms_type,
         "normalization": args.norm,
         "maximum_detections": args.max_detection,
         "warmup": args.warmup,
         "label offset": args.label_offset
     }
 
-    dataset = Dataset(
-        gformat=args.annotation_format,
-        absolute=args.absolute_annotations,
-        validate_type=args.validate
-    )
-    dataset = dataset.get_detection_dataset(
+    base_dataset = Dataset()
+    info_dataset = base_dataset.get_detection_dataset(
         source=args.dataset,
         labels_path=args.labels_file
+        )
+    dataset = instantiate_dataset(
+        info_dataset=info_dataset,
+        source=args.dataset,
+        gformat=args.annotation_format,
+        absolute=args.absolute_annotations,
+        validate_type=args.validate,
+        show_missing_annotations=args.show_missing_annotations
     )
 
     # DEEPVIEWRT EVALUATION
     if path.splitext(args.model)[1].lower() == ".rtm":
 
         if args.validate.lower() == "detection":
```

## deepview/validator/datasets/core.py

```diff
@@ -77,20 +77,21 @@
             in certain methods does not conform to the specified data type
             or the parameters are invalid. i.e. The image dimensions
             provided less than or equal to 0.
     """
 
     def __init__(
         self,
+        source=None,
         gformat='yolo',
         absolute=False,
         validate_type='detection',
         show_missing_annotations=False
     ):
-
+        self.source = source
         self.shape = None  # (height, width)
         self.format = gformat.lower()
         self.show_missing_annotations = show_missing_annotations
         self.absolute = absolute
         self.validate_type = validate_type
 
         if self.format not in ['yolo', 'pascalvoc', 'coco']:
@@ -157,22 +158,78 @@
                     "The provided path to the dataset is not a string. " +
                     "Recieved type: {}".format(
                         type(source)))
             if not os.path.exists(source):
                 raise DatasetNotFoundException(source)
             else:
                 return source
+    
+    @staticmethod
+    def read_yaml_file(file_path):
+        """
+        This function reads yaml files internal to AuZone for collecting
+        dataset information.
+        Unit-test for this function is defined under:
+            file: test/test_datasets.py
+            function: test_read_yaml_file
+
+        Parameters
+        ----------
+
+            file_path: str
+                The path to the yaml file.
+
+        Returns
+        -------
+            info_dataset: dict
+                This contains the yaml file contents.
+                For AuZoneRecords, the structure is defined as:
+                {
+                    "classes": [contains unique string labels of the dataset],
+                    "type": "darknet",
+                    "validation": {
+                        "path": the path to the *.tfrecord files
+                        }
+                }
+
+                For AuZoneNet, the structure is defined as:
+                {
+                    "classes": [contains unique string labels of the dataset],
+                    "validation": {
+                        "images": the path to the images,
+                        "annotations": the path to the label annotations
+                    }
+                }
 
-    def get_detection_dataset(self, source, labels_path=None):
+        Raises
+        ------
+            FileNotFoundError
+                    This method will raise an exception if the provided
+                    path to the labels.txt does not exist.
+        """
+
+        try:
+            import yaml
+        except ImportError:
+            pass
+
+        with open(file_path) as file:
+            return yaml.full_load(file)
+
+    def get_detection_dataset(
+        self,
+        source, 
+        labels_path=None
+        ):
         """
         This method inspects the *.yaml file contents if it exists.
         Otherwise it will search for either images with text
         annotations (Darknet) or tfrecord files (TFRecord Dataset).
         Unit-test for this method is defined under:
-            file: test/deepview/validator/datasets/test_core.py
+            file: test/test_datasets.py
             function: test_get_detection_dataset
 
         Parameters
         ----------
 
             source: str
                 The validated path to the dataset.
@@ -201,179 +258,107 @@
 
             EmptyDatasetException
                 This method will raise an exception if the path
                 provided does not contain any tfrecords, images,
                 or text annotations.
         """
 
-        from deepview.validator.datasets import TFRecordDataset
-        from deepview.validator.datasets import DarkNetDataset
+        source = Dataset.validate_input_source(source)
 
-        try:
-            import yaml
-        except ImportError:
-            pass
-
-        self.source = self.validate_input_source(source)
-
-        if os.path.isdir(self.source):
+        if os.path.isdir(source):
             # Handle AuZoneNet and AuZoneTFRecords format.
             filename = "dataset_info.yaml"
-            for root, _, files in os.walk(self.source):
+            labels_file = "labels.txt"
+            for root, _, files in os.walk(source):
                 if filename in files:
-
-                    with open(os.path.join(root, filename)) as file:
-                        info_dataset = yaml.full_load(file)
-
-                    ds_format = info_dataset.get('type')
-                    if ds_format in [None, "tfrecord"]:
-                        dataset = TFRecordDataset(
-                            info_dataset=info_dataset,
-                            gformat=self.format,
-                            absolute=self.absolute,
-                            validate_type=self.validate_type
-                        )
-                    elif ds_format == "darknet":
-                        dataset = DarkNetDataset(
-                            info_dataset=info_dataset,
-                            gformat=self.format,
-                            absolute=self.absolute,
-                            validate_type=self.validate_type,
-                            show_missing_annotations=self.show_missing_annotations)
-                    else:
-                        raise UnsupportedDatasetTypeException(ds_format)
-
-                    return dataset
-
-            if labels_path is None:
-                labels_file = "labels.txt"
-                for root, _, files in os.walk(self.source):
+                    return self.read_yaml_file(os.path.join(root, filename))
+            
+            if labels_path is None:  
+                for root, _, files in os.walk(source):
                     if labels_file in files:
                         labels_path = os.path.join(root, labels_file)
-                        break
 
             if labels_path is not None:
-                labels_path = self.validate_input_source(labels_path)
+                labels_path = Dataset.validate_input_source(labels_path)
                 if os.path.exists(labels_path):
                     with open(labels_path) as file:
                         labels = [line.rstrip().lower()
                                   for line in file.readlines()]
                 else:
                     raise FileNotFoundError(
                         f"Labels file does not exist at: {labels_path}")
             else:
                 labels = list()
 
             # Handles standard TFRecord datasets.
             info_dataset = dict()
-            tfrecord_files = glob(os.path.join(self.source, "*.tfrecord"))
+            tfrecord_files = glob(os.path.join(source, "*.tfrecord"))
             if len(tfrecord_files) != 0:
                 info_dataset["classes"] = labels
-                info_dataset["validation"] = {
-                    "path": self.source
-                }
-
-                dataset = TFRecordDataset(
-                    info_dataset=info_dataset,
-                    gformat=self.format,
-                    absolute=self.absolute,
-                    validate_type=self.validate_type
-                )
-
-                return dataset
+                info_dataset["validation"] = { "path": source }
+                return info_dataset
 
             # Handles standard Darknet datasets.
             image_files = list()
             info_dataset = dict()
             for extension in ['jpg', 'png', 'jpeg', 'JPG', 'PNG', 'JPEG']:
                 if len(image_files) == 0:
                     image_files = glob(
-                        os.path.join(self.source, f"*.{extension}")
+                        os.path.join(source, f"*.{extension}")
                     )
-                    image_source = self.source
+                    image_source = source
                     if len(image_files) == 0:
                         image_files = glob(os.path.join(
-                            self.source, f"images/validate/*.{extension}"))
+                            source, f"images/validate/*.{extension}"))
                         image_source = os.path.join(
-                            self.source, "images/validate"
+                            source, "images/validate"
                         )
                 else:
                     for ext in ['*.txt', '*.json']:
-                        annotation_files = glob(os.path.join(self.source, ext))
-                        annotation_source = self.source
+                        annotation_files = glob(os.path.join(source, ext))
+                        annotation_source = source
                         if len(annotation_files) == 0 or (
                             len(annotation_files) == 1 and os.path.basename(
                                 annotation_files[0]) == "labels.txt"):
                             annotation_files = glob(os.path.join(
-                                self.source, 'labels/validate/'+ ext))
+                                source, 'labels/validate/'+ ext))
                             annotation_source = os.path.join(
-                                self.source, "labels/validate")
+                                source, "labels/validate")
                             if len(annotation_files) == 0:
                                 continue
                             else:
                                 break
                         else:
                             break
                     
                     if len(annotation_files) == 0:
-                        raise EmptyDatasetException(
-                            "annotations", self.source
-                        )
+                        raise EmptyDatasetException("annotations", source)
 
+                    info_dataset["type"] = "darknet"
                     info_dataset["classes"] = labels
                     info_dataset["validation"] = {
                         "images": image_source,
                         "annotations": annotation_source
                     }
-                    dataset = DarkNetDataset(
-                        info_dataset=info_dataset,
-                        gformat=self.format,
-                        absolute=self.absolute,
-                        validate_type=self.validate_type,
-                        show_missing_annotations=self.show_missing_annotations
-                    )
-                    return dataset
-
-        elif os.path.isfile(self.source):
-            if os.path.basename(self.source) == "dataset_info.yaml":
-
-                with open(self.source) as file:
-                    info_dataset = yaml.full_load(file)
-
-                ds_format = info_dataset.get('type')
-                if ds_format in [None, "tfrecord"]:
-                    dataset = TFRecordDataset(
-                        info_dataset=info_dataset,
-                        gformat=self.format,
-                        absolute=self.absolute,
-                        validate_type=self.validate_type
-                    )
-                elif ds_format == "darknet":
-                    dataset = DarkNetDataset(
-                        info_dataset=info_dataset,
-                        gformat=self.format,
-                        absolute=self.absolute,
-                        validate_type=self.validate_type,
-                        show_missing_annotations=self.show_missing_annotations
-                    )
-                else:
-                    raise UnsupportedDatasetTypeException(ds_format)
-
-                return dataset
-
-            elif os.path.splitext(self.source)[1] == ".txt":
+                    return info_dataset
+                    
+        elif os.path.isfile(source):
+            if os.path.basename(source) == "dataset_info.yaml":
+                return self.read_yaml_file(source)
+            elif os.path.splitext(source)[1] == ".txt":
                 raise NotImplementedError(
                     "Single text file is not currently supported.")
-
-            elif os.path.splitext(self.source)[1] == ".deepview":
+            elif os.path.splitext(source)[1] == ".deepview":
                 raise NotImplementedError(
                     "Deepview files are not currently supported.")
-
             else:
-                UnsupportedDatasetTypeException(self.source)
+                UnsupportedDatasetTypeException(source)
+        
+        else:
+            UnsupportedDatasetTypeException(source)
 
     @staticmethod
     def validate_dimension(dimension):
         """
         This method validates the dimension
         either height or width to be of type
         integers and cannot be less than or equal to 0.
```

## deepview/validator/datasets/darknet.py

```diff
@@ -26,14 +26,17 @@
     same directory.
     Unit-test for this class is defined under:
         file: test/deepview/validator/datasets/test_darknet.py
 
     Parameters
     ----------
 
+        source: str
+            The path to the source dataset.
+
         info_dataset: dict
             Contains information such as :
 
             .. code-block:: python
 
                 {
                     "classes": [list of unique labels],
@@ -83,27 +86,32 @@
             This exception will be raised if the provided
             path to the images or text files does not contain
             any image files or text files respectively.
     """
 
     def __init__(
         self,
-        info_dataset,
+        source,
+        info_dataset=None,
         gformat='yolo',
         absolute=False,
         validate_type="detection",
         show_missing_annotations=False
     ):
         super(DarkNetDataset, self).__init__(
+            source=source,
             gformat=gformat,
             absolute=absolute,
             validate_type=validate_type,
             show_missing_annotations=show_missing_annotations
         )
 
+        if info_dataset is None:
+            info_dataset = self.get_detection_dataset(source)
+
         self.validate_type = validate_type.lower()
         self.image_source = self.validate_input_source(
             info_dataset.get('validation').get('images'))
         self.annotation_source = self.validate_input_source(
             info_dataset.get('validation').get('annotations'))
         self.labels = info_dataset.get('classes', None)
```

## deepview/validator/datasets/tfrecord.py

```diff
@@ -24,14 +24,17 @@
 
     Unit-test for this class is defined under:
         file: test/deepview/validator/datasets/test_tfrecord.py
 
     Parameters
     ----------
 
+        source: str
+            The path to the source dataset.
+
         info_dataset: dict
             Contains information such as:
 
             .. code-block:: python
 
                 {
                     "classes": [list of unique labels],
@@ -72,24 +75,29 @@
             path to the tfrecord files does not contain
             any tfrecord files.
     """
 
     def __init__(
         self,
         info_dataset,
+        source=None,
         gformat='yolo',
         absolute=False,
         validate_type='detection'
     ):
         super(TFRecordDataset, self).__init__(
+            source=source,
             gformat=gformat,
             absolute=absolute,
             validate_type=validate_type
         )
 
+        if info_dataset is None:
+            info_dataset = self.get_detection_dataset(source)
+
         self.source = self.validate_input_source(
             info_dataset.get('validation').get('path'))
         self.labels = info_dataset.get('classes', None)
 
         self.tfrecords = glob(join(self.source, '*.tfrecord'))
         if len(self.tfrecords) == 0:
             raise EmptyDatasetException(
```

## deepview/validator/runners/offline.py

 * *Ordering differences only*

```diff
@@ -4,17 +4,17 @@
 # Proprietary and confidential.
 #
 # This source code is provided solely for runtime interpretation by Python.
 # Modifying or copying any source code is explicitly forbidden.
 
 from deepview.validator.exceptions import UnsupportedAnnotationFormatException
 from deepview.validator.exceptions import NonMatchingIndexException
+from os.path import basename, splitext, join, exists
 from deepview.validator.datasets.core import Dataset
 from deepview.validator.runners.core import Runner
-from os.path import basename, splitext, join, exists
 import numpy as np
 import warnings
 
 
 class OfflineRunner(Runner):
     """
     This class reads model prediction annotations stored in text files
```

## deepview/validator/runners/modelclient/core.py

```diff
@@ -76,15 +76,15 @@
             import requests as req
         except ImportError:
             raise MissingLibraryException(
                 "requests is needed to communicate " +
                 "with the modelclient server.")
 
         try:
-            from modelclient import ModelClient
+            from deepview.rt.modelclient import ModelClient
             self.client = ModelClient(
                 uri=self.target,
                 rtm=self.model_path,
             )
         except req.exceptions.ConnectionError:
             raise ModelRunnerFailedConnectionException(self.target)
```

## deepview/validator/writers/core.py

```diff
@@ -462,10 +462,10 @@
             |     validation score threshold: {str(parameters.get("validation-threshold")).ljust(17)}|
             |     detection score threshold: {str(parameters.get("detection-threshold")).ljust(18)}|
             |     nms: {str(parameters.get("nms")).ljust(40)}|
             |     normalization: {str(parameters.get("normalization")).ljust(30)}|
             |     engine: {str(parameters.get('engine')).ljust(37)}|
             |     maximum detections: {str(parameters.get("maximum_detections")).ljust(25)}|
             |     warmup: {str(parameters.get("warmup")).ljust(37)}|
-            |     label offset: {str(parameters.get("label_offset")).ljust(31)}|
+            |     label offset: {str(parameters.get("label offset")).ljust(31)}|
             |__________________________________________________|
             """
```

## Comparing `deepview_validator-3.0.2.dist-info/RECORD` & `deepview_validator-3.0.3.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 deepview/validator/__init__.py,sha256=OjgWWA-EkgVtRfV0-4yBzPOGUB7AaRD-ipzY5gmq1I4,760
-deepview/validator/__main__.py,sha256=8sOPKDrdo2vVfEWdSwHqUIyxvFQJQ-SyPUnGwXp2PkM,15665
+deepview/validator/__main__.py,sha256=oXd9h9VvZfCSWQ52aV_VSau75ZfvOzIICR85JOcEv1Y,15914
 deepview/validator/exceptions.py,sha256=wN9LfxtSZ7jijwua-jziTBsrynjPS5Y8-nZerxBe5m4,12847
 deepview/validator/datasets/__init__.py,sha256=kn3O2am9aQkpCCUapanHpD2Hmqg2IXhMMduOY6LizYY,497
-deepview/validator/datasets/core.py,sha256=Cnhmxso5WJSGgRoAQUsUOhJ2EUz8tO-d8z1Khvg2w1Y,31118
-deepview/validator/datasets/darknet.py,sha256=JLD7bI5ys_UV19tNNxWs_GuvZ4w9kgLaTRktfdaYe_M,14296
-deepview/validator/datasets/tfrecord.py,sha256=sfsjBB_HqjcgD6WJC4oy5XNAL1498Ov1gnoyp9j1lz0,6820
+deepview/validator/datasets/core.py,sha256=Uo5fxKb_dX2eCUAfh-1B3PJD23y_kq4FO-FDPeJp64c,29989
+deepview/validator/datasets/darknet.py,sha256=Aypvp-JAUQL5rcm4Knny5AUfFfeNwExQbxU_3gdQcec,14505
+deepview/validator/datasets/tfrecord.py,sha256=tuMWxHPSazhzLdKlZv7tPVZVIzevEp7snIWgpT9zuDI,7029
+deepview/validator/datasets/utils.py,sha256=uFo47noinkjsD_88e5Gj1nSFHvyqFY0guLE7I4LWPlU,3786
 deepview/validator/evaluators/__init__.py,sha256=0UF3SF__Siagxw9ERwngKeVVz8DlNCiqUd2I_u8SJvI,530
 deepview/validator/evaluators/core.py,sha256=tcMB8G7z_5qeXMD8hojl9Avl-nOsUm4IjMD1lVX1MCg,5067
 deepview/validator/evaluators/detectionevaluator.py,sha256=z85dWpX4oZ3ckMiU4jZ2Sg_fDJjOW9er75iGRlSLchY,24515
 deepview/validator/evaluators/segmentationevaluator.py,sha256=3hVpduQLVRKGhEhcNQT22OMUfNPPn2Y5kv3dTARyx4Y,18731
 deepview/validator/metrics/__init__.py,sha256=vp8Dy7OR0tzfFsBPv81Y2OYWetgWrAHRzfBzkkNtazY,830
 deepview/validator/metrics/core.py,sha256=zfqUyymrWuFhQo2VbxhR36cw6dTuI7Vk1z-pKKLFBgU,11297
 deepview/validator/metrics/detectiondata.py,sha256=Y5XeGWdaZjcYpOcvx67d2yOSTIynCBxKTVVdOAzQbEg,31668
@@ -17,27 +18,27 @@
 deepview/validator/metrics/segmentationdata.py,sha256=pW1KijcEyhWwIP-DOsEnQe0ACXJeOIezSRneCjqlglE,17211
 deepview/validator/metrics/segmentationmetrics.py,sha256=SwydgF85ql4nO_jUgPZeIV6Y9rwIS9_0POPu4CTV_Og,6319
 deepview/validator/metrics/segmentationutils.py,sha256=bbD5xAz-xCLcoaRXFHDYW7Zc_L8oqyVJ2ccItC5YtCc,11704
 deepview/validator/runners/__init__.py,sha256=RpTNgMnmfh7LrQwMZk8RJOawR8lPBP1tpY8wt8sO-Ao,674
 deepview/validator/runners/core.py,sha256=gVikDHobZPPeQxvK1eRzaoKgert1RlJQQBHpz-3zBg4,5144
 deepview/validator/runners/deepviewrt.py,sha256=KgJhzm_HpQuydzjiI7TKt6wUo2k-rodQcv49wj-p_eE,13596
 deepview/validator/runners/keras.py,sha256=bc4arQLR0WPLjStqQek0Xe_Xxg6pzQHmS6hAG3SBotY,14335
-deepview/validator/runners/offline.py,sha256=PaOKOsWEj0Jy4NCjigELvpv8nvxEdgfiZNT23ngty6w,6147
+deepview/validator/runners/offline.py,sha256=DTcgg7LmuUXUuUmFw5qEo0IAYjjgaVaG0lpNCKAzqbM,6147
 deepview/validator/runners/tensorrt.py,sha256=OMBziiYWUeJWmjonHo5QlQZMXSDppHAOx0CDJFEZAfY,16285
 deepview/validator/runners/tflite.py,sha256=yJst2M2ae2ID003msEKu03gpKgxykRWjzGMFssffM2A,15389
 deepview/validator/runners/modelclient/__init__.py,sha256=xAXPMiSEFRfLGKbT7uCiutSxvzWkVrdN9HNx2XUVMKI,600
 deepview/validator/runners/modelclient/boxes.py,sha256=_j7gKuS7Vw0iYT6b8ocmX4qiPzc2HrH17_TgkM89D2c,29387
-deepview/validator/runners/modelclient/core.py,sha256=VobJQ5nS0NN6x6vFrHTqU2re7LmOI0O0ejczgyBmji8,3104
+deepview/validator/runners/modelclient/core.py,sha256=1zK1SxMojNnEk6-BT8tRdyMroad2Bvg9vs5vu9-dNTw,3116
 deepview/validator/runners/modelclient/segmentation.py,sha256=7n8Xf7ZB5c3tL2q87QLCkBJlETq2r1wNLdN33DG2ZuI,11846
 deepview/validator/visualize/__init__.py,sha256=gGM_U0YR1SOagPIhUjQr8PLJAPZ-XzHuY9jLwg3uHds,521
 deepview/validator/visualize/core.py,sha256=qELc2h8wID5ROWiVUeLFZkgBUzO8KCQiQkJUqR_ZFgc,11059
 deepview/validator/visualize/detectiondrawer.py,sha256=3CMifGWwfx4cuKNwE8WLgmEGRIBaFewfTjmknlpPJeg,7014
 deepview/validator/visualize/segmentationdrawer.py,sha256=Ub7TixeNRleaDcN4c3wXHQ0xtUDuXpvd4cABsxfKB8o,14479
 deepview/validator/writers/__init__.py,sha256=PAF-P5kc2h-0VYIz6KL5Z4jgzpKcu4ulIeDsOldKTjE,574
 deepview/validator/writers/console.py,sha256=oIDnZdDtlc0snO24ODN_-54vrdWrvUB0J3AI08RCtuE,7611
-deepview/validator/writers/core.py,sha256=R49s9-hxzTA47d4XzUErGn2sjK3Yi7ArEfXfJbkKrLA,19839
+deepview/validator/writers/core.py,sha256=zSZ58ByNrJbTyJqDb8Tohw-SvzJj3CoAqoyf963vfG4,19839
 deepview/validator/writers/tensorboard.py,sha256=NxzZolLWfAlz1G8gyOZxYRlYmzM0F2KijPrHkKvA8nE,9065
-deepview_validator-3.0.2.dist-info/METADATA,sha256=3Zlen5ojjoOM6ADzArvfXlVnJMmJrs5JOn6nJfHCt08,433
-deepview_validator-3.0.2.dist-info/WHEEL,sha256=nvhOrkn7_9sGzJjxuUFjoJ6OkO7SJJqHSjq9VNu0Elc,92
-deepview_validator-3.0.2.dist-info/entry_points.txt,sha256=n4jIdEDC_mPGVLwmS21vEFC8_D7mqNuekZYdtupSSVE,73
-deepview_validator-3.0.2.dist-info/top_level.txt,sha256=FZ_uj5ZExs9dTNq5lw196yb-XR3VHKi6vS0EWgTQtXk,9
-deepview_validator-3.0.2.dist-info/RECORD,,
+deepview_validator-3.0.3.dist-info/METADATA,sha256=HTpgtqA-b28cG2mK9rVrIjpVATxwrTVwTA6hE0BsluM,433
+deepview_validator-3.0.3.dist-info/WHEEL,sha256=nvhOrkn7_9sGzJjxuUFjoJ6OkO7SJJqHSjq9VNu0Elc,92
+deepview_validator-3.0.3.dist-info/entry_points.txt,sha256=n4jIdEDC_mPGVLwmS21vEFC8_D7mqNuekZYdtupSSVE,73
+deepview_validator-3.0.3.dist-info/top_level.txt,sha256=FZ_uj5ZExs9dTNq5lw196yb-XR3VHKi6vS0EWgTQtXk,9
+deepview_validator-3.0.3.dist-info/RECORD,,
```

