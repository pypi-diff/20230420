# Comparing `tmp/sparsezoo_nightly-1.5.0.20230418-py3-none-any.whl.zip` & `tmp/sparsezoo_nightly-1.5.0.20230420-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,69 +1,69 @@
-Zip file size: 131412 bytes, number of entries: 67
--rw-rw-r--  2.0 unx     1002 b- defN 23-Apr-18 00:30 sparsezoo/__init__.py
--rw-rw-r--  2.0 unx     5138 b- defN 23-Apr-18 00:30 sparsezoo/analytics.py
--rw-rw-r--  2.0 unx     4090 b- defN 23-Apr-18 00:30 sparsezoo/analyze_cli.py
--rw-rw-r--  2.0 unx     3015 b- defN 23-Apr-18 00:30 sparsezoo/download_main.py
--rw-rw-r--  2.0 unx    14757 b- defN 23-Apr-18 00:30 sparsezoo/main.py
--rw-rw-r--  2.0 unx     4134 b- defN 23-Apr-18 00:30 sparsezoo/package.py
--rw-rw-r--  2.0 unx     1492 b- defN 23-Apr-18 00:30 sparsezoo/version.py
--rw-rw-r--  2.0 unx      685 b- defN 23-Apr-18 00:30 sparsezoo/analyze/__init__.py
--rw-rw-r--  2.0 unx    46300 b- defN 23-Apr-18 00:30 sparsezoo/analyze/analysis.py
--rw-rw-r--  2.0 unx     5517 b- defN 23-Apr-18 00:30 sparsezoo/analyze/cli.py
--rw-rw-r--  2.0 unx      633 b- defN 23-Apr-18 00:30 sparsezoo/analyze/utils/__init__.py
--rw-rw-r--  2.0 unx    14722 b- defN 23-Apr-18 00:30 sparsezoo/analyze/utils/chart.py
--rw-rw-r--  2.0 unx     6969 b- defN 23-Apr-18 00:30 sparsezoo/analyze/utils/models.py
--rw-rw-r--  2.0 unx      732 b- defN 23-Apr-18 00:30 sparsezoo/api/__init__.py
--rw-rw-r--  2.0 unx     1332 b- defN 23-Apr-18 00:30 sparsezoo/api/exceptions.py
--rw-rw-r--  2.0 unx     2915 b- defN 23-Apr-18 00:30 sparsezoo/api/graphql.py
--rw-rw-r--  2.0 unx     6332 b- defN 23-Apr-18 00:30 sparsezoo/api/query_parser.py
--rw-rw-r--  2.0 unx     1750 b- defN 23-Apr-18 00:30 sparsezoo/api/utils.py
--rw-rw-r--  2.0 unx      653 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/__init__.py
--rw-rw-r--  2.0 unx     7694 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/cli.py
--rw-rw-r--  2.0 unx     2138 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/main.py
--rw-rw-r--  2.0 unx      886 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/docker/Dockerfile
--rw-rw-r--  2.0 unx      898 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/docker/helpers.py
--rw-rw-r--  2.0 unx      680 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/utils/__init__.py
--rw-rw-r--  2.0 unx     3450 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/utils/extractors.py
--rw-rw-r--  2.0 unx    12563 b- defN 23-Apr-18 00:30 sparsezoo/deployment_package/utils/utils.py
--rw-rw-r--  2.0 unx      666 b- defN 23-Apr-18 00:30 sparsezoo/inference/__init__.py
--rw-rw-r--  2.0 unx     5813 b- defN 23-Apr-18 00:30 sparsezoo/inference/inference_runner.py
--rw-rw-r--  2.0 unx      676 b- defN 23-Apr-18 00:30 sparsezoo/model/__init__.py
--rw-rw-r--  2.0 unx    27803 b- defN 23-Apr-18 00:30 sparsezoo/model/model.py
--rw-rw-r--  2.0 unx     2127 b- defN 23-Apr-18 00:30 sparsezoo/model/result_utils.py
--rw-rw-r--  2.0 unx    22638 b- defN 23-Apr-18 00:30 sparsezoo/model/utils.py
--rw-rw-r--  2.0 unx      706 b- defN 23-Apr-18 00:30 sparsezoo/objects/__init__.py
--rw-rw-r--  2.0 unx     9619 b- defN 23-Apr-18 00:30 sparsezoo/objects/directories.py
--rw-rw-r--  2.0 unx    11279 b- defN 23-Apr-18 00:30 sparsezoo/objects/directory.py
--rw-rw-r--  2.0 unx    11323 b- defN 23-Apr-18 00:30 sparsezoo/objects/file.py
--rw-rw-r--  2.0 unx      656 b- defN 23-Apr-18 00:30 sparsezoo/search/__init__.py
--rw-rw-r--  2.0 unx     5796 b- defN 23-Apr-18 00:30 sparsezoo/search/search.py
--rw-rw-r--  2.0 unx     1238 b- defN 23-Apr-18 00:30 sparsezoo/utils/__init__.py
--rw-rw-r--  2.0 unx     5449 b- defN 23-Apr-18 00:30 sparsezoo/utils/authentication.py
--rw-rw-r--  2.0 unx    11681 b- defN 23-Apr-18 00:30 sparsezoo/utils/calculate_ops.py
--rw-rw-r--  2.0 unx     3993 b- defN 23-Apr-18 00:30 sparsezoo/utils/constants.py
--rw-rw-r--  2.0 unx    11125 b- defN 23-Apr-18 00:30 sparsezoo/utils/data.py
--rw-rw-r--  2.0 unx     6835 b- defN 23-Apr-18 00:30 sparsezoo/utils/download.py
--rw-rw-r--  2.0 unx     1877 b- defN 23-Apr-18 00:30 sparsezoo/utils/gdpr.py
--rw-rw-r--  2.0 unx     9003 b- defN 23-Apr-18 00:30 sparsezoo/utils/graph_editor.py
--rw-rw-r--  2.0 unx     2647 b- defN 23-Apr-18 00:30 sparsezoo/utils/helpers.py
--rw-rw-r--  2.0 unx    11721 b- defN 23-Apr-18 00:30 sparsezoo/utils/node_inference.py
--rw-rw-r--  2.0 unx     8786 b- defN 23-Apr-18 00:30 sparsezoo/utils/numpy.py
--rw-rw-r--  2.0 unx    14420 b- defN 23-Apr-18 00:30 sparsezoo/utils/onnx.py
--rw-rw-r--  2.0 unx     3269 b- defN 23-Apr-18 00:30 sparsezoo/utils/task_name.py
--rw-rw-r--  2.0 unx      935 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/__init__.py
--rw-rw-r--  2.0 unx     2833 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/feature_status.py
--rw-rw-r--  2.0 unx     6783 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/feature_status_page.py
--rw-rw-r--  2.0 unx     5935 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/feature_status_table.py
--rw-rw-r--  2.0 unx     2376 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/markdown_utils.py
--rw-rw-r--  2.0 unx     4112 b- defN 23-Apr-18 00:30 sparsezoo/utils/standardization/write_status_pages.py
--rw-rw-r--  2.0 unx      687 b- defN 23-Apr-18 00:30 sparsezoo/validation/__init__.py
--rw-rw-r--  2.0 unx     2117 b- defN 23-Apr-18 00:30 sparsezoo/validation/integrations.py
--rw-rw-r--  2.0 unx     8780 b- defN 23-Apr-18 00:30 sparsezoo/validation/validator.py
--rw-rw-r--  2.0 unx    11353 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/LICENSE
--rw-rw-r--  2.0 unx    19825 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/METADATA
--rw-rw-r--  2.0 unx     1414 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/NOTICE
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/WHEEL
--rw-rw-r--  2.0 unx      217 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       10 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6030 b- defN 23-Apr-18 00:30 sparsezoo_nightly-1.5.0.20230418.dist-info/RECORD
-67 files, 415122 bytes uncompressed, 121760 bytes compressed:  70.7%
+Zip file size: 135099 bytes, number of entries: 67
+-rw-rw-r--  2.0 unx     1002 b- defN 23-Apr-20 00:30 sparsezoo/__init__.py
+-rw-rw-r--  2.0 unx     5138 b- defN 23-Apr-20 00:30 sparsezoo/analytics.py
+-rw-rw-r--  2.0 unx     5048 b- defN 23-Apr-20 00:30 sparsezoo/analyze_cli.py
+-rw-rw-r--  2.0 unx     3015 b- defN 23-Apr-20 00:30 sparsezoo/download_main.py
+-rw-rw-r--  2.0 unx    14757 b- defN 23-Apr-20 00:30 sparsezoo/main.py
+-rw-rw-r--  2.0 unx     4134 b- defN 23-Apr-20 00:30 sparsezoo/package.py
+-rw-rw-r--  2.0 unx     1492 b- defN 23-Apr-20 00:30 sparsezoo/version.py
+-rw-rw-r--  2.0 unx      685 b- defN 23-Apr-20 00:30 sparsezoo/analyze/__init__.py
+-rw-rw-r--  2.0 unx    52910 b- defN 23-Apr-20 00:30 sparsezoo/analyze/analysis.py
+-rw-rw-r--  2.0 unx     5518 b- defN 23-Apr-20 00:30 sparsezoo/analyze/cli.py
+-rw-rw-r--  2.0 unx      633 b- defN 23-Apr-20 00:30 sparsezoo/analyze/utils/__init__.py
+-rw-rw-r--  2.0 unx    14722 b- defN 23-Apr-20 00:30 sparsezoo/analyze/utils/chart.py
+-rw-rw-r--  2.0 unx    15684 b- defN 23-Apr-20 00:30 sparsezoo/analyze/utils/models.py
+-rw-rw-r--  2.0 unx      732 b- defN 23-Apr-20 00:30 sparsezoo/api/__init__.py
+-rw-rw-r--  2.0 unx     1332 b- defN 23-Apr-20 00:30 sparsezoo/api/exceptions.py
+-rw-rw-r--  2.0 unx     2915 b- defN 23-Apr-20 00:30 sparsezoo/api/graphql.py
+-rw-rw-r--  2.0 unx     6332 b- defN 23-Apr-20 00:30 sparsezoo/api/query_parser.py
+-rw-rw-r--  2.0 unx     1750 b- defN 23-Apr-20 00:30 sparsezoo/api/utils.py
+-rw-rw-r--  2.0 unx      653 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/__init__.py
+-rw-rw-r--  2.0 unx     7694 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/cli.py
+-rw-rw-r--  2.0 unx     2138 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/main.py
+-rw-rw-r--  2.0 unx      886 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/docker/Dockerfile
+-rw-rw-r--  2.0 unx      898 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/docker/helpers.py
+-rw-rw-r--  2.0 unx      680 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/utils/__init__.py
+-rw-rw-r--  2.0 unx     3450 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/utils/extractors.py
+-rw-rw-r--  2.0 unx    12563 b- defN 23-Apr-20 00:30 sparsezoo/deployment_package/utils/utils.py
+-rw-rw-r--  2.0 unx      666 b- defN 23-Apr-20 00:30 sparsezoo/inference/__init__.py
+-rw-rw-r--  2.0 unx     5813 b- defN 23-Apr-20 00:30 sparsezoo/inference/inference_runner.py
+-rw-rw-r--  2.0 unx      676 b- defN 23-Apr-20 00:30 sparsezoo/model/__init__.py
+-rw-rw-r--  2.0 unx    27803 b- defN 23-Apr-20 00:30 sparsezoo/model/model.py
+-rw-rw-r--  2.0 unx     2127 b- defN 23-Apr-20 00:30 sparsezoo/model/result_utils.py
+-rw-rw-r--  2.0 unx    22638 b- defN 23-Apr-20 00:30 sparsezoo/model/utils.py
+-rw-rw-r--  2.0 unx      706 b- defN 23-Apr-20 00:30 sparsezoo/objects/__init__.py
+-rw-rw-r--  2.0 unx     9619 b- defN 23-Apr-20 00:30 sparsezoo/objects/directories.py
+-rw-rw-r--  2.0 unx    11279 b- defN 23-Apr-20 00:30 sparsezoo/objects/directory.py
+-rw-rw-r--  2.0 unx    11323 b- defN 23-Apr-20 00:30 sparsezoo/objects/file.py
+-rw-rw-r--  2.0 unx      656 b- defN 23-Apr-20 00:30 sparsezoo/search/__init__.py
+-rw-rw-r--  2.0 unx     5796 b- defN 23-Apr-20 00:30 sparsezoo/search/search.py
+-rw-rw-r--  2.0 unx     1238 b- defN 23-Apr-20 00:30 sparsezoo/utils/__init__.py
+-rw-rw-r--  2.0 unx     5449 b- defN 23-Apr-20 00:30 sparsezoo/utils/authentication.py
+-rw-rw-r--  2.0 unx    11681 b- defN 23-Apr-20 00:30 sparsezoo/utils/calculate_ops.py
+-rw-rw-r--  2.0 unx     3993 b- defN 23-Apr-20 00:30 sparsezoo/utils/constants.py
+-rw-rw-r--  2.0 unx    11125 b- defN 23-Apr-20 00:30 sparsezoo/utils/data.py
+-rw-rw-r--  2.0 unx     6835 b- defN 23-Apr-20 00:30 sparsezoo/utils/download.py
+-rw-rw-r--  2.0 unx     1877 b- defN 23-Apr-20 00:30 sparsezoo/utils/gdpr.py
+-rw-rw-r--  2.0 unx     9003 b- defN 23-Apr-20 00:30 sparsezoo/utils/graph_editor.py
+-rw-rw-r--  2.0 unx     2647 b- defN 23-Apr-20 00:30 sparsezoo/utils/helpers.py
+-rw-rw-r--  2.0 unx    11721 b- defN 23-Apr-20 00:30 sparsezoo/utils/node_inference.py
+-rw-rw-r--  2.0 unx     8786 b- defN 23-Apr-20 00:30 sparsezoo/utils/numpy.py
+-rw-rw-r--  2.0 unx    14420 b- defN 23-Apr-20 00:30 sparsezoo/utils/onnx.py
+-rw-rw-r--  2.0 unx     3269 b- defN 23-Apr-20 00:30 sparsezoo/utils/task_name.py
+-rw-rw-r--  2.0 unx      935 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/__init__.py
+-rw-rw-r--  2.0 unx     2833 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/feature_status.py
+-rw-rw-r--  2.0 unx     6783 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/feature_status_page.py
+-rw-rw-r--  2.0 unx     5935 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/feature_status_table.py
+-rw-rw-r--  2.0 unx     2376 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/markdown_utils.py
+-rw-rw-r--  2.0 unx     4112 b- defN 23-Apr-20 00:30 sparsezoo/utils/standardization/write_status_pages.py
+-rw-rw-r--  2.0 unx      687 b- defN 23-Apr-20 00:30 sparsezoo/validation/__init__.py
+-rw-rw-r--  2.0 unx     2117 b- defN 23-Apr-20 00:30 sparsezoo/validation/integrations.py
+-rw-rw-r--  2.0 unx     8780 b- defN 23-Apr-20 00:30 sparsezoo/validation/validator.py
+-rw-rw-r--  2.0 unx    11353 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/LICENSE
+-rw-rw-r--  2.0 unx    19825 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/METADATA
+-rw-rw-r--  2.0 unx     1414 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/NOTICE
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/WHEEL
+-rw-rw-r--  2.0 unx      217 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       10 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6031 b- defN 23-Apr-20 00:30 sparsezoo_nightly-1.5.0.20230420.dist-info/RECORD
+67 files, 431407 bytes uncompressed, 125447 bytes compressed:  70.9%
```

## zipnote {}

```diff
@@ -174,29 +174,29 @@
 
 Filename: sparsezoo/validation/integrations.py
 Comment: 
 
 Filename: sparsezoo/validation/validator.py
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/LICENSE
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/LICENSE
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/METADATA
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/METADATA
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/NOTICE
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/NOTICE
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/WHEEL
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/WHEEL
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/entry_points.txt
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/entry_points.txt
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/top_level.txt
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/top_level.txt
 Comment: 
 
-Filename: sparsezoo_nightly-1.5.0.20230418.dist-info/RECORD
+Filename: sparsezoo_nightly-1.5.0.20230420.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sparsezoo/analyze_cli.py

```diff
@@ -59,56 +59,88 @@
     sparsezoo.analyze ~/models/resnet50.onnx \
     --save resnet50-analysis.yaml
 """
 import logging
 from typing import Optional
 
 import click
+from sparsezoo import convert_to_bool
 from sparsezoo.analytics import sparsezoo_analytics
 from sparsezoo.analyze import ModelAnalysis
 from sparsezoo.analyze.cli import CONTEXT_SETTINGS, analyze_options
 
 
 __all__ = ["main"]
 
 
-LOGGER = logging.getLogger()
+_LOGGER = logging.getLogger(__name__)
 
 
 @click.command(context_settings=CONTEXT_SETTINGS)
 @analyze_options
 @sparsezoo_analytics.send_event_decorator("cli__main")
-def main(model_path: str, save: Optional[str], **kwargs):
+def main(
+    model_path: str,
+    compare: Optional[str],
+    save: Optional[str],
+    by_layers: Optional[str],
+    by_types: Optional[str],
+    **kwargs,
+):
     """
     Model analysis for ONNX models.
 
     MODEL_PATH: can be a SparseZoo stub, or local path to a
     deployment-directory or ONNX model
 
     Examples:
 
     - Run model analysis on resnet
 
         sparsezoo.analyze ~/models/resnet50.onnx
     """
     logging.basicConfig(level=logging.INFO)
 
-    for unimplemented_feat in ("compare", "by_layer", "by_types", "save_graphs"):
+    for unimplemented_feat in ("save_graphs",):
         if kwargs.get(unimplemented_feat):
             raise NotImplementedError(
                 f"--{unimplemented_feat} has not been implemented yet"
             )
 
-    LOGGER.info("Starting Analysis ...")
+    _LOGGER.info("Starting Analysis ...")
     analysis = ModelAnalysis.create(model_path)
-    LOGGER.info("Analysis complete, collating results...")
+    _LOGGER.info("Analysis complete, collating results...")
 
-    print(f"MODEL: {model_path}", end="\n\n")
-    analysis.pretty_print_summary()
+    by_types: bool = convert_to_bool(by_types)
+    by_layers: bool = convert_to_bool(by_layers)
+
+    summary = analysis.summary(
+        by_types=by_types,
+        by_layers=by_layers,
+    )
+    summary.pretty_print()
+
+    if compare is not None:
+        if "," in compare:
+            compare = compare.split(",")
+        else:
+            compare = [compare]
+
+        print("Comparison Analysis!!!")
+        for model_to_compare in compare:
+            compare_model_analysis = ModelAnalysis.create(model_to_compare)
+            summary_comparison_model = compare_model_analysis.summary(
+                by_types=by_types,
+                by_layers=by_layers,
+            )
+            print(f"Comparing {model_path} with {model_to_compare}")
+            print("Note: comparison analysis displays differences b/w models")
+            comparison = summary - summary_comparison_model
+            comparison.pretty_print()
 
     if save:
-        LOGGER.info(f"Writing results to {save}")
+        _LOGGER.info(f"Writing results to {save}")
         analysis.yaml(file_path=save)
 
 
 if __name__ == "__main__":
     main()
```

## sparsezoo/analyze/analysis.py

```diff
@@ -14,35 +14,43 @@
 """
 A module that contains schema definitions for benchmarking and/or performance
 analysis results
 """
 
 import copy
 import logging
+import warnings
 from collections import defaultdict
 from dataclasses import dataclass
 from pathlib import Path
 from typing import Any, Dict, List, Optional, Union
 
 import numpy
 import onnx
 import yaml
 from onnx import ModelProto, NodeProto
 from pydantic import BaseModel, Field, PositiveFloat, PositiveInt
 
-import pandas
 from sparsezoo import Model
 from sparsezoo.analyze.utils.models import (
     DenseSparseOps,
+    Entry,
+    ModelEntry,
+    NamedEntry,
     NodeCounts,
     NodeIO,
+    NodeTimingEntry,
     OperationSummary,
     OpsSummary,
     ParameterComponent,
     ParameterSummary,
+    PerformanceEntry,
+    Section,
+    SizedModelEntry,
+    TypedEntry,
     ZeroNonZeroParams,
 )
 from sparsezoo.utils import (
     NodeDataType,
     NodeShape,
     ONNXGraph,
     extract_node_id,
@@ -69,14 +77,25 @@
     "BenchmarkScenario",
     "BenchmarkResult",
     "NodeAnalysis",
     "ModelAnalysis",
 ]
 
 _LOGGER = logging.getLogger()
+TARGETED_LINEAR_OP_TYPES = {
+    "Conv",
+    "ConvInteger",
+    "ConvTranspose",
+    "DeformConv",
+    "QLinearConv",
+    "MatMul",
+    "MatMulInteger",
+    "QLinearMatMul",
+    "Gemm",
+}
 
 
 class YAMLSerializableBaseModel(BaseModel):
     """
     A BaseModel that adds a .yaml(...) function to all child classes
     """
 
@@ -92,14 +111,33 @@
         )
 
         if file_stream is not None:
             file_stream.close()
 
         return ret
 
+    @classmethod
+    def parse_yaml_file(cls, file_path: str):
+        """
+        :param file_path: path to yaml file containing model analysis data
+        :return: instance of ModelAnalysis class
+        """
+        with open(file_path, "r") as file:
+            dict_obj = yaml.safe_load(file)
+        return cls.parse_obj(dict_obj)
+
+    @classmethod
+    def parse_yaml_raw(cls, yaml_raw: str):
+        """
+        :param yaml_raw: string containing model analysis data
+        :return: instance of ModelAnalysis class
+        """
+        dict_obj = yaml.safe_load(yaml_raw)  # unsafe: needs to load numpy
+        return cls.parse_obj(dict_obj)
+
 
 @dataclass
 class _SparseItemCount:
     name: str
     total: int = 0
     pruned: int = 0
     dense: int = 0
@@ -227,14 +265,19 @@
     )
 
     node_timings: Optional[List[NodeInferenceResult]] = Field(
         default=None,
         description="Node level inference results",
     )
 
+    supported_graph_percentage: Optional[float] = Field(
+        default=None,
+        description="Percentage of model graph supported by the runtime engine",
+    )
+
 
 class NodeAnalysis(YAMLSerializableBaseModel):
     """
     Pydantic model for the analysis of a node within a model
     """
 
     name: str = Field(description="The node's name")
@@ -563,14 +606,265 @@
             parameterized_prunable=is_parameterized_prunable_layer(model_graph, node),
             sparse_node=sparse_node,
             quantized_node=quantized_node,
             zero_point=get_zero_point(model_graph, node),
         )
 
 
+class CountSummary(BaseModel):
+    items: List[_SparseItemCount]
+    _precision: int = 2
+
+    @property
+    def total(self):
+        return sum(item.total for item in self.items)
+
+    @property
+    def sparse_count(self):
+        return sum(item.pruned for item in self.items)
+
+    @property
+    def dense_count(self):
+        return sum(item.dense for item in self.items)
+
+    @property
+    def quant_count(self):
+        return sum(item.quantized for item in self.items)
+
+    @property
+    def sparsity_percent(self):
+        return round(self.sparse_count * 100.0 / self.total, self._precision)
+
+    @property
+    def quantized_percent(self):
+        return round(self.quant_count * 100.0 / self.total, self._precision)
+
+    @property
+    def size(self):
+        """
+        :return: size in bits ignoring zeros
+        """
+        return (self.quant_count * 8 + self.dense_count * 32) * (
+            1 - self.sparsity_percent / 100.0
+        )
+
+    def __add__(self, other):
+        new_items = self.items + other.items
+        return self.__class__(items=new_items)
+
+
+class ModelAnalysisSummary(Entry, YAMLSerializableBaseModel):
+    sections: List[Section]
+
+    def pretty_print(self):
+        """
+        Convenience function to pretty print ModelAnalysisSummary(...) objects
+        """
+
+        for section in self.sections:
+            section.pretty_print()
+
+    @classmethod
+    def from_model_analysis(
+        cls,
+        analysis: "ModelAnalysis",
+        by_types: bool = False,
+        by_layers: bool = False,
+        **kwargs,
+    ) -> "ModelAnalysisSummary":
+        """
+        Factory method to generate a ModelAnalysisSummary object from a
+        sparsezoo.ModelAnalysis object
+
+        :param analysis: The ModelAnalysis object which the newly created
+            ModelAnalysisSummary object will summarize
+        :param by_types: flag to summarize analysis information by param and
+            op type
+        :param by_layers: flag to summarize analysis information by layers
+        :returns: A ModelAnalysisSummary that summarizes current analysis based
+            on specified arguments
+        """
+        sections = []
+
+        if by_layers:
+            _LOGGER.info("Running analysis `by_layers`")
+            by_layers_entries = []
+            for node in analysis.nodes:
+                if node.op_type not in TARGETED_LINEAR_OP_TYPES:
+                    # do not include in layer-wise analysis
+                    continue
+                precision_dict = node.parameter_summary.precision
+                dense = 0
+                quantized = 0
+                for precision, counts in precision_dict.items():
+                    if "32" in precision:
+                        # include float32, int32
+                        dense += counts.total
+                    else:
+                        # TODO: Add support for different precisions
+                        quantized += counts.total
+
+                node_count_summary = CountSummary(
+                    items=[
+                        _SparseItemCount(
+                            name=node.name,
+                            total=node.parameter_summary.total,
+                            pruned=node.parameter_summary.pruned,
+                            dense=dense,
+                            quantized=quantized,
+                        )
+                    ]
+                )
+                entry = NamedEntry(
+                    name=node.name,
+                    total=node_count_summary.total,
+                    size=node_count_summary.size,
+                    sparsity=node_count_summary.sparsity_percent,
+                    quantized=node_count_summary.quantized_percent,
+                )
+                by_layers_entries.append(entry)
+            if by_layers_entries:
+                sections.append(
+                    Section(
+                        section_name="Analysis by Layers",
+                        entries=by_layers_entries,
+                    )
+                )
+
+        # Add Param analysis section
+        param_count_summary: CountSummary = _get_param_count_summary(analysis=analysis)
+        param_section = Section(
+            section_name="Params",
+            entries=[
+                SizedModelEntry(
+                    model=analysis.model_name,
+                    count=param_count_summary.total,
+                    size=param_count_summary.size,
+                    sparsity=param_count_summary.sparsity_percent,
+                    quantized=param_count_summary.quantized_percent,
+                ),
+            ],
+        )
+
+        # Add Ops analysis section
+        ops_count_summary: CountSummary = _get_ops_count_summary(analysis=analysis)
+        ops_section = Section(
+            section_name="Ops",
+            entries=[
+                SizedModelEntry(
+                    model=analysis.model_name,
+                    count=ops_count_summary.total,
+                    size=ops_count_summary.size,
+                    sparsity=ops_count_summary.sparsity_percent,
+                    quantized=ops_count_summary.quantized_percent,
+                ),
+            ],
+        )
+        if by_types:
+            _LOGGER.info("Running analysis `by_types`")
+
+            entries = []
+            for item in param_count_summary.items:
+                item_count_summary = CountSummary(items=[item])
+                entry = TypedEntry(
+                    type=item.name,
+                    size=item_count_summary.size,
+                    sparsity=item_count_summary.sparsity_percent,
+                    quantized=item_count_summary.quantized_percent,
+                )
+                entries.append(entry)
+
+            entries.append(
+                TypedEntry(
+                    type="Total",
+                    size=param_count_summary.size,
+                    sparsity=param_count_summary.sparsity_percent,
+                    quantized=param_count_summary.quantized_percent,
+                )
+            )
+
+            type_param_section = Section(
+                section_name="Parameters by types",
+                entries=entries,
+            )
+
+            sections.append(type_param_section)
+            entries = []
+            for item in ops_count_summary.items:
+                item_count_summary = CountSummary(items=[item])
+                entry = TypedEntry(
+                    type=item.name,
+                    size=item_count_summary.size,
+                    sparsity=item_count_summary.sparsity_percent,
+                    quantized=item_count_summary.quantized_percent,
+                )
+                entries.append(entry)
+
+            entries.append(
+                TypedEntry(
+                    type="Total",
+                    size=ops_count_summary.size,
+                    sparsity=ops_count_summary.sparsity_percent,
+                    quantized=ops_count_summary.quantized_percent,
+                )
+            )
+            type_ops_section = Section(section_name="Ops by types", entries=entries)
+
+            sections.append(type_ops_section)
+
+        # Add Overall model analysis section
+        overall_count_summary: CountSummary = param_count_summary + ops_count_summary
+        if not analysis.benchmark_results:
+
+            overall_section = Section(
+                section_name="Overall",
+                entries=[
+                    ModelEntry(
+                        model=analysis.model_name,
+                        sparsity=overall_count_summary.sparsity_percent,
+                        quantized=overall_count_summary.quantized_percent,
+                    )
+                ],
+            )
+
+        else:
+            overall_section = Section(
+                section_name="Overall",
+                entries=[
+                    PerformanceEntry(
+                        model=analysis.model_name,
+                        sparsity=overall_count_summary.sparsity_percent,
+                        quantized=overall_count_summary.quantized_percent,
+                        latency=benchmark_result.average_latency,
+                        throughput=benchmark_result.items_per_second,
+                        supported_graph=(
+                            benchmark_result.supported_graph_percentage or 0.0
+                        ),
+                    )
+                    for idx, benchmark_result in enumerate(analysis.benchmark_results)
+                ],
+            )
+
+            for idx, benchmark_result in enumerate(analysis.benchmark_results):
+                node_timing_section = Section(
+                    section_name=f"Node Timings for Benchmark # {idx+1}",
+                    entries=[
+                        NodeTimingEntry(
+                            node_name=node_timing.name,
+                            avg_runtime=node_timing.avg_run_time,
+                        )
+                        for node_timing in benchmark_result.node_timings
+                    ],
+                )
+                sections.append(node_timing_section)
+
+        sections.extend([param_section, ops_section, overall_section])
+        return cls(sections=sections)
+
+
 class ModelAnalysis(YAMLSerializableBaseModel):
     """
     Pydantic model for analysis of a model
     """
 
     node_counts: Dict[str, int] = Field(description="The number of each node op type")
     all_nodes: NodeCounts = Field(
@@ -588,14 +882,19 @@
     parameter_summary: ParameterSummary = Field(
         description="A summary of all the parameters in the model"
     )
     operation_summary: OperationSummary = Field(
         description="A summary of all the operations in the model"
     )
 
+    model_name: str = Field(
+        description="Optional model name, defaults to empty string",
+        default="",
+    )
+
     nodes: List[NodeAnalysis] = Field(
         description="List of analyses for each node in the model graph", default=[]
     )
 
     benchmark_results: List[BenchmarkResult] = Field(
         default=[],
         description="A list of different benchmarking results for the onnx model",
@@ -607,29 +906,31 @@
         Model Analysis
 
         :param cls: class being constructed
         :param onnx_file_path: path to onnx file, or a loaded onnx ModelProto to
             analyze
         :return: instance of cls
         """
-        model_onnx = (
-            onnx_file_path
-            if isinstance(onnx_file_path, ModelProto)
-            else onnx.load(onnx_file_path)
-        )
+        if isinstance(onnx_file_path, ModelProto):
+            model_onnx = onnx_file_path
+            model_name = ""
+        else:
+            model_onnx = onnx.load(onnx_file_path)
+            model_name = str(onnx_file_path)
+
         model_graph = ONNXGraph(model_onnx)
 
         node_analyses = cls.analyze_nodes(model_graph)
 
         layer_counts, op_counts = get_layer_and_op_counts(model_graph)
         layer_counts.update(op_counts)
         node_counts = layer_counts.copy()
 
-        # these could be done with node-wise computation rather than feature-wise
-        # to reduce run time
+        # these could be done with node-wise computation rather than
+        # feature-wise to reduce run time
 
         all_nodes = NodeCounts(
             total=len(node_analyses),
             quantized=len(
                 [1 for node_analysis in node_analyses if node_analysis.quantized_node]
             ),
             # quantizable
@@ -957,14 +1258,15 @@
                     )
                     for dtype in all_macs_operation_dtypes
                 },
             ),
         )
 
         return cls(
+            model_name=model_name,
             node_counts=node_counts,
             all_nodes=all_nodes,
             parameterized=parameterized,
             non_parameterized=non_parameterized,
             parameter_summary=parameter_summary,
             operation_summary=operation_summary,
             nodes=node_analyses,
@@ -986,234 +1288,77 @@
         if not isinstance(file_path, (str, ModelProto, Path)):
             raise ValueError(
                 f"Invalid file_path type {type(file_path)} passed to "
                 f"ModelAnalysis.create(...)"
             )
 
         if isinstance(file_path, ModelProto):
-            return ModelAnalysis.from_onnx(onnx_file_path=file_path)
+            result = ModelAnalysis.from_onnx(onnx_file_path=file_path)
 
-        if Path(file_path).is_file():
-            return (
+        elif Path(file_path).is_file():
+            result = (
                 ModelAnalysis.parse_yaml_file(file_path=file_path)
                 if Path(file_path).suffix == ".yaml"
                 else ModelAnalysis.from_onnx(onnx_file_path=file_path)
             )
-        if Path(file_path).is_dir():
+        elif Path(file_path).is_dir():
             _LOGGER.info(f"Loading `model.onnx` from deployment directory {file_path}")
-            return ModelAnalysis.from_onnx(Path(file_path) / "model.onnx")
+            result = ModelAnalysis.from_onnx(Path(file_path) / "model.onnx")
 
-        if file_path.startswith("zoo:"):
-            return ModelAnalysis.from_onnx(
+        elif file_path.startswith("zoo:"):
+            result = ModelAnalysis.from_onnx(
                 Model(file_path).deployment.get_file("model.onnx").path
             )
 
-        if isinstance(file_path, str):
-            return ModelAnalysis.parse_yaml_raw(yaml_raw=file_path)
+        elif isinstance(file_path, str):
+            result = ModelAnalysis.parse_yaml_raw(yaml_raw=file_path)
+        else:
+            raise ValueError(
+                f"Invalid argument file_path {file_path} to create ModelAnalysis"
+            )
 
-        raise ValueError(
-            f"Invalid argument file_path {file_path} to create ModelAnalysis"
-        )
+        result.model_name = file_path
+        return result
 
-    def summary(self) -> Dict[str, Any]:
+    def summary(self, **kwargs) -> ModelAnalysisSummary:
         """
-        :return: A dict like object with summary of current analysis
+        :return: A ModelAnalysisSummary object that represents summary of
+            current analyses
         """
-
-        # parameter summary
-
-        alias_to_item_count: Dict[str, _SparseItemCount] = {
-            name.lower(): _SparseItemCount(name=name) for name in ["Weight", "Bias"]
-        }
-
-        for node in self.nodes:
-            for parameter in node.parameters:
-                item_count = alias_to_item_count[parameter.alias]
-                parameter_summary = parameter.parameter_summary
-
-                item_count.total += parameter_summary.total
-                item_count.pruned += parameter_summary.pruned
-
-                if "float32" in parameter_summary.precision:
-                    item_count.dense += (
-                        parameter_summary.precision["float32"].zero
-                        + parameter_summary.precision["float32"].non_zero
-                    )
-
-        parameter_item_counts = list(alias_to_item_count.values())
-
-        # fill empty quantized counts
-
-        for item_count in parameter_item_counts:
-            item_count.quantized = item_count.total - item_count.dense
-
-        parameter_summary = {
-            "Parameters": _summary_from_sparse_item_counts(items=parameter_item_counts),
-        }
-
-        # ops summary
-
-        pruned_param_counts = defaultdict(int)
-        dense_param_counts = defaultdict(int)
-        total_param_counts = defaultdict(int)
-        parameterized_op_types = set()
-
-        sparse_node_counts = defaultdict(int)
-        dense_node_counts = defaultdict(int)
-        total_node_counts = defaultdict(int)
-        non_parameterized_op_types = set()
-
-        for node in self.nodes:
-            if node.parameterized_prunable:
-                parameterized_op_types.add(node.op_type)
-                pruned_param_counts[node.op_type] += node.parameter_summary.pruned
-                total_param_counts[node.op_type] += node.parameter_summary.total
-
-                if "float32" in node.parameter_summary.precision:
-                    dense_param_counts[node.op_type] += (
-                        node.parameter_summary.precision["float32"].zero
-                        + node.parameter_summary.precision["float32"].non_zero
-                    )
-
-            else:
-                non_parameterized_op_types.add(node.op_type)
-                total_node_counts[node.op_type] += 1
-                if node.sparse_node:
-                    sparse_node_counts[node.op_type] += 1
-                if not node.quantized_node:
-                    dense_node_counts[node.op_type] += 1
-
-        parameterized_item_counts = [
-            _SparseItemCount(
-                name=op_type,
-                total=total_param_counts[op_type],
-                pruned=pruned_param_counts[op_type],
-                dense=dense_param_counts[op_type],
-                quantized=total_param_counts[op_type] - dense_param_counts[op_type],
-            )
-            for op_type in parameterized_op_types
-        ]
-
-        non_parameterized_item_counts = [
-            _SparseItemCount(
-                name=op_type,
-                total=total_node_counts[op_type],
-                pruned=sparse_node_counts[op_type],
-                dense=dense_node_counts[op_type],
-                quantized=total_node_counts[op_type] - dense_node_counts[op_type],
-            )
-            for op_type in non_parameterized_op_types
-        ]
-
-        ops_summary = {
-            "Parameterized Ops": _summary_from_sparse_item_counts(
-                items=parameterized_item_counts,
-            ),
-            "Non Parameterized Ops": _summary_from_sparse_item_counts(
-                items=non_parameterized_item_counts,
-            ),
-        }
-
-        footer = {
-            "Summary": {
-                "Number of Parameters": parameter_summary["Parameters"]["Total"][
-                    "Total"
-                ],
-                "Number of Operations": sum(
-                    op_summary["Total"]["Total"] for op_summary in ops_summary.values()
-                ),
-                "Weight Sparsity %": parameter_summary["Parameters"]["Weight"][
-                    "Sparsity %"
-                ],
-                "Quantized Parameterized Ops %": ops_summary["Parameterized Ops"][
-                    "Total"
-                ]["INT8 Precision %"],
-                "Quantized Non-Parameterized Ops %": ops_summary[
-                    "Non Parameterized Ops"
-                ]["Total"]["INT8 Precision %"],
-            }
-        }
-
-        # performance summary
-
-        performance_summary = {}
-        if self.benchmark_results:
-            performance_summary = {
-                "OVERALL": self._get_benchmark_summary(
-                    ops_summary=ops_summary,
-                    parameter_summary=parameter_summary,
-                )
-            }
-
-        return {
-            **parameter_summary,
-            **ops_summary,
-            **performance_summary,
-            **footer,
-        }
-
-    def _get_benchmark_summary(self, ops_summary, parameter_summary):
-        if not self.benchmark_results:
-            return {}
-
-        return {
-            f"Benchmark {idx + 1}": {
-                "Latency(ms)": benchmark_result.average_latency,
-                "Throughput(itm/sec)": benchmark_result.items_per_second,
-                "Supported Graph %": "",
-                "Sparsity %": (
-                    benchmark_result.imposed_sparsification.sparsity
-                    or parameter_summary["Parameters"]["Weight"]["Sparsity %"]
-                ),
-                "Quantized Parameterized Ops %": ops_summary["Parameterized Ops"][
-                    "Total"
-                ]["INT8 Precision %"],
-                "Quantized Non-Parameterized Ops %": ops_summary[
-                    "Non Parameterized Ops"
-                ]["Total"]["INT8 Precision %"],
-            }
-            for idx, benchmark_result in enumerate(self.benchmark_results)
-        }
+        return ModelAnalysisSummary.from_model_analysis(analysis=self, **kwargs)
 
     def pretty_print_summary(self):
         """
         Pretty print analysis summary
+        Note: pretty_print_summary() method will be deprecated from
+        `ModelAnalysis` class in a future version, use
+        `self.summary(...).pretty_print()` instead, where `self` is an object
+        of `ModelAnalysis` class
         """
+        warnings.warn(
+            "my_regrettable_function will be retired in version 1.0, please "
+            "use my_awesome_function instead.",
+            DeprecationWarning,
+            stacklevel=2,
+        )
+        import pandas
+
         summary = self.summary()
         summary_copy = copy.copy(summary)
         footer = summary_copy.pop("Summary")
 
         # relies on pandas for pretty printing as of now
         for section_name, section_dict in summary_copy.items():
             print(f"{section_name.upper()}:")
             print(pandas.DataFrame(section_dict).T.to_string(), end="\n\n")
 
         print("SUMMARY:")
         for footer_key, footer_value in footer.items():
             print(f"{footer_key}: {footer_value}")
 
-    @classmethod
-    def parse_yaml_file(cls, file_path: str):
-        """
-        :param file_path: path to yaml file containing model analysis data
-        :return: instance of ModelAnalysis class
-        """
-        with open(file_path, "r") as file:
-            dict_obj = yaml.safe_load(file)
-        return cls.parse_obj(dict_obj)
-
-    @classmethod
-    def parse_yaml_raw(cls, yaml_raw: str):
-        """
-        :param yaml_raw: string containing model analysis data
-        :return: instance of ModelAnalysis class
-        """
-        dict_obj = yaml.safe_load(yaml_raw)  # unsafe: needs to load numpy
-        return cls.parse_obj(dict_obj)
-
     @staticmethod
     def analyze_nodes(model_graph: ONNXGraph) -> List[NodeAnalysis]:
         """
         :param: model that contains the nodes to be analyzed
         :return: list of node analyses from model graph
         """
         node_shapes, node_dtypes = extract_node_shapes_and_dtypes(model_graph.model)
@@ -1227,37 +1372,89 @@
                 model_graph, node, node_shape=node_shape, node_dtype=node_dtype
             )
             nodes.append(node_analysis)
 
         return nodes
 
 
-def _summary_from_sparse_item_counts(items: List[_SparseItemCount], precision: int = 2):
-    """
-    :return: A dict like object with stats about each item type
-    """
-    total = sum(item.total for item in items)
-    num_sparse = sum(item.pruned for item in items)
-    num_fp32 = sum(item.dense for item in items)
-    num_int8 = sum(item.quantized for item in items)
-
-    summary = {
-        item.name: {
-            "Total": item.total,
-            "Percent Total %": round(item.total * 100.0 / total, precision),
-            "Sparsity %": round(item.pruned * 100.0 / item.total, precision),
-            "FP32 Precision %": round(item.dense * 100.0 / item.total, precision),
-            "INT8 Precision %": round(item.quantized * 100.0 / item.total, precision),
-        }
-        for item in items
-        if item.total
+def _get_param_count_summary(analysis: ModelAnalysis) -> CountSummary:
+    alias_to_item_count: Dict[str, _SparseItemCount] = {
+        name.lower(): _SparseItemCount(name=name) for name in ["Weight", "Bias"]
     }
 
-    summary["Total"] = {
-        "Total": total,
-        "Percent Total %": round(total * 100.0 / total, precision),
-        "Sparsity %": round(num_sparse * 100.0 / total, precision),
-        "FP32 Precision %": round(num_fp32 * 100.0 / total, precision),
-        "INT8 Precision %": round(num_int8 * 100.0 / total, precision),
-    }
+    for node in analysis.nodes:
+        for parameter in node.parameters:
+            item_count = alias_to_item_count[parameter.alias]
+            parameter_summary = parameter.parameter_summary
+
+            item_count.total += parameter_summary.total
+            item_count.pruned += parameter_summary.pruned
+
+            for precision, count in parameter_summary.precision.items():
+                if "32" in precision:
+                    # fp32 and int32
+                    item_count.dense += count.total
+                else:
+                    # TODO: Add support for other precisions
+                    item_count.quantized += count.total
+
+    return CountSummary(items=list(alias_to_item_count.values()))
+
+
+def _get_ops_count_summary(analysis: ModelAnalysis) -> CountSummary:
+    # ops summary
+
+    pruned_param_counts = defaultdict(int)
+    dense_param_counts = defaultdict(int)
+    total_param_counts = defaultdict(int)
+    parameterized_op_types = set()
+
+    sparse_node_counts = defaultdict(int)
+    dense_node_counts = defaultdict(int)
+    total_node_counts = defaultdict(int)
+    non_parameterized_op_types = set()
+
+    for node in analysis.nodes:
+        if node.parameterized_prunable:
+            parameterized_op_types.add(node.op_type)
+            pruned_param_counts[node.op_type] += node.parameter_summary.pruned
+            total_param_counts[node.op_type] += node.parameter_summary.total
+
+            if "float32" in node.parameter_summary.precision:
+                dense_param_counts[node.op_type] += (
+                    node.parameter_summary.precision["float32"].zero
+                    + node.parameter_summary.precision["float32"].non_zero
+                )
+
+        else:
+            non_parameterized_op_types.add(node.op_type)
+            total_node_counts[node.op_type] += 1
+            if node.sparse_node:
+                sparse_node_counts[node.op_type] += 1
+            if not node.quantized_node:
+                dense_node_counts[node.op_type] += 1
+
+    parameterized_item_counts = [
+        _SparseItemCount(
+            name=op_type,
+            total=total_param_counts[op_type],
+            pruned=pruned_param_counts[op_type],
+            dense=dense_param_counts[op_type],
+            quantized=total_param_counts[op_type] - dense_param_counts[op_type],
+        )
+        for op_type in parameterized_op_types
+    ]
+
+    non_parameterized_item_counts = [
+        _SparseItemCount(
+            name=op_type,
+            total=total_node_counts[op_type],
+            pruned=sparse_node_counts[op_type],
+            dense=dense_node_counts[op_type],
+            quantized=total_node_counts[op_type] - dense_node_counts[op_type],
+        )
+        for op_type in non_parameterized_op_types
+    ]
 
-    return summary
+    return CountSummary(
+        items=[*parameterized_item_counts, *non_parameterized_item_counts]
+    )
```

## sparsezoo/analyze/cli.py

```diff
@@ -80,15 +80,15 @@
         "--by-types",
         default=None,
         type=str,
         help="A flag to enable analysis results by operator type. If set or "
         "boolean string, generates and records the results by operator type",
     )
     @click.option(
-        "--by-layer",
+        "--by-layers",
         default=None,
         type=str,
         help="A flag to enable analysis results by layer type. If set or "
         "boolean string, generates and records the results across all layers",
     )
     @functools.wraps(command)
     def wrap_common_options(*args, **kwargs):
```

## sparsezoo/analyze/utils/models.py

```diff
@@ -7,16 +7,17 @@
 #    http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing,
 # software distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
-
-from typing import Dict, List, Optional, Union
+import logging
+import textwrap
+from typing import Dict, List, Optional, Tuple, Union
 
 from pydantic import BaseModel, Field
 
 
 __all__ = [
     "NodeCounts",
     "NodeIO",
@@ -24,14 +25,16 @@
     "DenseSparseOps",
     "ParameterSummary",
     "OpsSummary",
     "OperationSummary",
     "ParameterComponent",
 ]
 
+_LOGGER = logging.getLogger(__name__)
+
 
 class PropertyBaseModel(BaseModel):
     """
     https://github.com/samuelcolvin/pydantic/issues/935#issuecomment-1152457432
 
     Workaround for serializing properties with pydantic until
     https://github.com/samuelcolvin/pydantic/issues/935
@@ -120,20 +123,24 @@
     )
     non_zero: int = Field(
         description="The number of parameters whose value is zero", default=0
     )
 
     @property
     def sparsity(self):
-        total_values = self.non_zero + self.zero
+        total_values = self.total
         if total_values > 0:
             return self.zero / total_values
         else:
             return 0
 
+    @property
+    def total(self):
+        return self.non_zero + self.zero
+
 
 class DenseSparseOps(PropertyBaseModel):
     """
     Pydantic model for specifying the number dense and sparse operations and the
     associated operation sparsity
     """
 
@@ -217,7 +224,291 @@
     shape: Optional[List[Union[None, int]]] = Field(
         description="The shape of the parameter"
     )
     parameter_summary: ParameterSummary = Field(
         description="A summary of the parameter"
     )
     dtype: str = Field(description="The data type of the parameter")
+
+
+class Entry(BaseModel):
+    """
+    A BaseModel with subtraction and pretty_print support
+    """
+
+    _print_order: List[str] = []
+
+    def __sub__(self, other):
+        """
+        Allows base functionality for all inheriting classes to be subtract-able,
+        subtracts the fields of self with other while providing some additional
+        support for string and unrolling list type fields
+        """
+        my_fields = self.__fields__
+        other_fields = other.__fields__
+
+        assert list(my_fields) == list(other_fields)
+        new_fields = {}
+        for field in my_fields:
+            if field.startswith("_"):
+                # ignore private fields
+                continue
+            my_value = getattr(self, field)
+            other_value = getattr(other, field)
+
+            assert type(my_value) == type(other_value)
+            if field == "section_name":
+                new_fields[field] = my_value
+            elif isinstance(my_value, str):
+                new_fields[field] = (
+                    my_value
+                    if my_value == other_value
+                    else f"{my_value} - {other_value}"
+                )
+            elif isinstance(my_value, list):
+                new_fields[field] = [
+                    item_a - item_b for item_a, item_b in zip(my_value, other_value)
+                ]
+            else:
+                new_fields[field] = my_value - other_value
+
+        return self.__class__(**new_fields)
+
+    def pretty_print(self, headers: bool = False, column_width=30):
+        """
+        pretty print current Entry object with all it's fields
+        """
+        field_names = self._print_order
+        field_values = []
+        for field_name in field_names:
+            field_value = getattr(self, field_name)
+            if isinstance(field_value, float):
+                field_value = f"{field_value:.2f}"
+            field_values.append(field_value)
+
+        if headers:
+            print(
+                multiline_pretty_print(
+                    row=[field_name.upper() for field_name in field_names],
+                    column_width=column_width,
+                )
+            )
+        print(multiline_pretty_print(row=field_values, column_width=column_width))
+
+
+class BaseEntry(Entry):
+    """
+    The BaseModel representing a row entry
+
+    :param sparsity: A float between 0-100 representing sparsity percentage
+    :param quantized: A float between 0-100 representing quantized percentage
+    """
+
+    sparsity: float
+    quantized: float
+
+    _print_order = ["sparsity", "quantized"]
+
+
+class NamedEntry(BaseEntry):
+    """
+    BaseEntry with additional info like name, total and size
+    """
+
+    name: str
+    total: float
+    size: int
+
+    _print_order = ["name", "total", "size"] + BaseEntry._print_order
+
+
+class TypedEntry(BaseEntry):
+    """
+    BaseEntry with additional info like type and size
+    """
+
+    type: str
+    size: int
+
+    _print_order = ["type", "size"] + BaseEntry._print_order
+
+
+class ModelEntry(BaseEntry):
+    """
+    BaseEntry which includes name of the model
+    """
+
+    model: str
+    _print_order = ["model"] + BaseEntry._print_order
+
+
+class SizedModelEntry(ModelEntry):
+    """
+    A ModelEntry with additional info like count and size
+    """
+
+    count: int
+    size: int
+    _print_order = ModelEntry._print_order + ["count", "size"]
+
+
+class PerformanceEntry(BaseEntry):
+    """
+    A BaseEntry with additional performance info
+    """
+
+    model: str
+    latency: float
+    throughput: float
+    supported_graph: float
+
+    _print_order = [
+        "model",
+        "latency",
+        "throughput",
+        "supported_graph",
+    ] + BaseEntry._print_order
+
+
+class NodeTimingEntry(Entry):
+    """
+    A BaseEntry with additional performance info
+    """
+
+    node_name: str
+    avg_runtime: float
+
+    _print_order = [
+        "node_name",
+        "avg_runtime",
+    ] + Entry._print_order
+
+
+class Section(Entry):
+    """
+    Represents a list of Entries with an optional name
+    """
+
+    entries: List[
+        Union[
+            NodeTimingEntry,
+            PerformanceEntry,
+            NamedEntry,
+            TypedEntry,
+            SizedModelEntry,
+            ModelEntry,
+            BaseEntry,
+        ]
+    ]
+
+    section_name: str = ""
+
+    def pretty_print(self):
+        """
+        pretty print current section, with its entries
+        """
+        if self.section_name:
+            if not self.entries:
+                print(f"No entries found in: {self.section_name}")
+            else:
+                print(f"{self.section_name}:")
+
+        for idx, entry in enumerate(self.entries):
+            if idx == 0:
+                entry.pretty_print(headers=True)
+            else:
+                entry.pretty_print(headers=False)
+        print()
+
+    def __sub__(self, other: "Section"):
+        """
+        A method that allows us to subtract two Section objects,
+        If the section includes `NamedEntry` or `TypedEntry` then we only compare
+        the entries which have the same name or type (and others will be ignored),
+        Subtraction of other Entry types is delegated to their own implementation
+        This function also assumes that a Section has entries of the same type
+        """
+
+        if not isinstance(other, Section):
+            raise TypeError(
+                f"unsupported operand type(s) for -: {type(self)} and {type(other)}"
+            )
+
+        section_name = self.section_name or ""
+        self_entries, other_entries = self.get_comparable_entries(other)
+
+        compared_entries = [
+            self_entry - other_entry
+            for self_entry, other_entry in zip(self_entries, other_entries)
+        ]
+
+        return Section(
+            section_name=section_name,
+            entries=compared_entries,
+        )
+
+    def get_comparable_entries(self, other: "Section") -> Tuple[List[Entry], ...]:
+        """
+        Get comparable entries by same name or type if they belong to
+        `NamedEntry`, `TypedEntry`, or `NodeTimingEntry`, else return all entries
+
+        :return: A tuple composed of two lists, containing comparable entries
+            in correct order from current and other Section objects
+        """
+        assert self.entries
+        entry_type_to_extractor = {
+            "NamedEntry": lambda entry: entry.name,
+            "TypedEntry": lambda entry: entry.type,
+            "NodeTimingEntry": lambda entry: entry.node_name,
+        }
+        entry_type = self.entries[0].__class__.__name__
+
+        if entry_type not in entry_type_to_extractor:
+            return self.entries, other.entries
+
+        key_extractor = entry_type_to_extractor[entry_type]
+        self_entry_dict = {key_extractor(entry): entry for entry in self.entries}
+        other_entry_dict = {key_extractor(entry): entry for entry in other.entries}
+
+        self_comparable_entries = []
+        other_comparable_entries = []
+
+        for key, value in self_entry_dict.items():
+            if key in other_entry_dict:
+                self_comparable_entries.append(value)
+                other_comparable_entries.append(other_entry_dict[key])
+
+        if len(self_comparable_entries) != len(self_entry_dict):
+            _LOGGER.info(
+                "Found mismatching entries, these will be ignored during "
+                f"comparison in Section: {self.section_name}"
+            )
+        return self_comparable_entries, other_comparable_entries
+
+
+def multiline_pretty_print(row: List[str], column_width=20) -> str:
+    """
+    Formats the contents of the specified row into a multiline string which
+    each column is wrapped into a multiline string if its length is greater
+    than the specified column_width
+
+    :param row: A list of strings to be formatted into a multiline row
+    :param column_width: The max width of each column for formatting, default is 20
+    :returns: A multiline formatted string representing the row,
+    """
+    row = [str(column) for column in row]
+    result_string = ""
+    col_delim = " "
+    wrapped_row = [textwrap.wrap(col, column_width) for col in row]
+    max_lines_needed = max(len(col) for col in wrapped_row)
+
+    for line_idx in range(max_lines_needed):
+        result_string += col_delim
+        for column in wrapped_row:
+            if line_idx < len(column):
+                result_string += column[line_idx].ljust(column_width)
+            else:
+                result_string += " " * column_width
+            result_string += col_delim
+        if line_idx < max_lines_needed - 1:
+            result_string += "\n"
+    return result_string
```

## Comparing `sparsezoo_nightly-1.5.0.20230418.dist-info/LICENSE` & `sparsezoo_nightly-1.5.0.20230420.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sparsezoo_nightly-1.5.0.20230418.dist-info/METADATA` & `sparsezoo_nightly-1.5.0.20230420.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sparsezoo-nightly
-Version: 1.5.0.20230418
+Version: 1.5.0.20230420
 Summary: Neural network model repository for highly sparse and sparse-quantized models with matching sparsification recipes
 Home-page: https://github.com/neuralmagic/sparsezoo
 Author: Neuralmagic, Inc.
 Author-email: support@neuralmagic.com
 License: Apache
 Keywords: inference,machine learning,neural network,deep learning model,models,computer vision,nlp,pretrained transfer learning,sparsity,pruning,quantization,sparse models,resnet,mobilenet,yolov3
 Platform: UNKNOWN
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: sparsezoo-nightly Version: 1.5.0.20230418 Summary:
+Metadata-Version: 2.1 Name: sparsezoo-nightly Version: 1.5.0.20230420 Summary:
 Neural network model repository for highly sparse and sparse-quantized models
 with matching sparsification recipes Home-page: https://github.com/neuralmagic/
 sparsezoo Author: Neuralmagic, Inc. Author-email: support@neuralmagic.com
 License: Apache Keywords: inference,machine learning,neural network,deep
 learning model,models,computer vision,nlp,pretrained transfer
 learning,sparsity,pruning,quantization,sparse models,resnet,mobilenet,yolov3
 Platform: UNKNOWN Classifier: Development Status :: 5 - Production/Stable
```

## Comparing `sparsezoo_nightly-1.5.0.20230418.dist-info/NOTICE` & `sparsezoo_nightly-1.5.0.20230420.dist-info/NOTICE`

 * *Files identical despite different names*

## Comparing `sparsezoo_nightly-1.5.0.20230418.dist-info/RECORD` & `sparsezoo_nightly-1.5.0.20230420.dist-info/RECORD`

 * *Files 19% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 sparsezoo/__init__.py,sha256=Ibkd7FPpqDLPnq1JBT5UTGMdt71VNJqew-PejiTXC4Q,1002
 sparsezoo/analytics.py,sha256=Ju6xBh-BAdz8ShGsxYru02rlZJznxmrIdrvdD0R11sQ,5138
-sparsezoo/analyze_cli.py,sha256=eNdczM21gtZes5OjD0jj-J1iO326zRwpb_k-PC78Cu0,4090
+sparsezoo/analyze_cli.py,sha256=LiiwjqtnXZleh3am68jko2UdVaQiWsDb6-vyRdWRhls,5048
 sparsezoo/download_main.py,sha256=VNIyy7y-6ihi2Mmbz1Ng5wE3YcPLrZu0CbgqNqkhMUk,3015
 sparsezoo/main.py,sha256=_N-Y-nzOigQo1qWPCRudS5Qh9SzVCE3pPVgv8j0JEQs,14757
 sparsezoo/package.py,sha256=inDNel1Ks662jClI7CfkzLds0_swGqjjLAOQ92wwOF0,4134
 sparsezoo/version.py,sha256=IN1sgnHD9KyJqYPd6YVPr-BgKyFdf-2vA9c5T09wQIM,1492
 sparsezoo/analyze/__init__.py,sha256=590JFn3Pv1EFtNEHL9JPQjEyU-xmB9EMVxrZnGjo8pk,685
-sparsezoo/analyze/analysis.py,sha256=1EXgaW8Ftq2dAxJOKv9ETp_jN1aOeUObp7LPxtc3knc,46300
-sparsezoo/analyze/cli.py,sha256=Qo-PSpnacRmvocP9ts6kYq0MB7i3JLnJwte0qMlHSuI,5517
+sparsezoo/analyze/analysis.py,sha256=iRVKXZ7J3WUhxNu15BNO0Hzmt5brP-2ifWQRuoligAo,52910
+sparsezoo/analyze/cli.py,sha256=q_IisGLSsEMQaHVM6pad6-wbaLDNQv_8BiYFbNPp0D8,5518
 sparsezoo/analyze/utils/__init__.py,sha256=TF5uEKrpc2qYdbgmXh9xVp2GQ3p--by-LoCegY19EeI,633
 sparsezoo/analyze/utils/chart.py,sha256=eJbJTe60PYxvGU0fHxd88Lbjk-YKMd8uO5zoZkby-Hc,14722
-sparsezoo/analyze/utils/models.py,sha256=wB8ZNruSCeNVEaKD2zEMrJA-V1Fkq3GYKKjOYAw-CRE,6969
+sparsezoo/analyze/utils/models.py,sha256=ZWGb_nVBiBsdPXOukf_guE9stBLyN0RmNgP_OI6UKMQ,15684
 sparsezoo/api/__init__.py,sha256=7gwqr30TpkQoWsd6mLpUecSkKZmogMGVLdgo5fMW3Go,732
 sparsezoo/api/exceptions.py,sha256=DiM7FxdG7ktuY1EjhNheSPXUZjcyyFxtqjNarp0Bg-8,1332
 sparsezoo/api/graphql.py,sha256=sGhU2vVVI07Pq0QrONLcG-YVSbdzAE6OGy0MtBB5KGg,2915
 sparsezoo/api/query_parser.py,sha256=UjsCYoaHm2m4CBzT856opI6sRktCkH4j4U0wrvItKcw,6332
 sparsezoo/api/utils.py,sha256=vhrlo1JOg4hXQrirH2D0XxaU1hiLMvlvm6IxfW2QB_M,1750
 sparsezoo/deployment_package/__init__.py,sha256=hwgyNki_YjqwOjt4i6c3m45Bwcx78Hf4vs2jzCkHPv4,653
 sparsezoo/deployment_package/cli.py,sha256=qCQKCFFHTMRUfOJgRXhv_M0tWoB5nOuBXWZ-niYor9E,7694
@@ -54,14 +54,14 @@
 sparsezoo/utils/standardization/feature_status_page.py,sha256=F6F1pIvwzcixKyu6vj6Kw_ZIwV1ZwFdj9lhqObwxlkY,6783
 sparsezoo/utils/standardization/feature_status_table.py,sha256=p3BPpgcBF5GKpngt8iqSeqb9mHgtTTlaj8cEVDKz6Jw,5935
 sparsezoo/utils/standardization/markdown_utils.py,sha256=MjnZ9JFwZ9_mZ2-fG-MJPBWYnSL9MNqQ2qxLeGr0bFw,2376
 sparsezoo/utils/standardization/write_status_pages.py,sha256=K4ZscAX_xKl-d4ZQ2z4fEc4qGAcLHYCrsDTd9wV0xBc,4112
 sparsezoo/validation/__init__.py,sha256=3nxA-dWMpSjQ4Sz4kkRQP6cr2L7rZEvoNd1RCZiswAg,687
 sparsezoo/validation/integrations.py,sha256=aVLvdFQs7K1KzGFUNLe5La67MjNHW0yNaRXdJdRgI00,2117
 sparsezoo/validation/validator.py,sha256=x918oFHrvhJImljoweYvF0PVMO1sqJNwT0HKGfEXyy0,8780
-sparsezoo_nightly-1.5.0.20230418.dist-info/LICENSE,sha256=1KsbiqMUywdsP8MBywGsGxGf0Di1PHm1XIjWC24QNps,11353
-sparsezoo_nightly-1.5.0.20230418.dist-info/METADATA,sha256=u6uNA5oowlFBjtU9lfPXfYRCWfw0CRitJUlkO992HHw,19825
-sparsezoo_nightly-1.5.0.20230418.dist-info/NOTICE,sha256=naAyHz-LxMVCUVA27ssHBRIifnAixYvIhas5XTnEiO8,1414
-sparsezoo_nightly-1.5.0.20230418.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
-sparsezoo_nightly-1.5.0.20230418.dist-info/entry_points.txt,sha256=2tpzvrHBD--Om3jpHnfw1gx6EqA2IPFqnfJIl-RPX3o,217
-sparsezoo_nightly-1.5.0.20230418.dist-info/top_level.txt,sha256=SE5RMAyyIBKn6fDrXXF33MqdfB2Am0a9n9HRLAcrcZI,10
-sparsezoo_nightly-1.5.0.20230418.dist-info/RECORD,,
+sparsezoo_nightly-1.5.0.20230420.dist-info/LICENSE,sha256=1KsbiqMUywdsP8MBywGsGxGf0Di1PHm1XIjWC24QNps,11353
+sparsezoo_nightly-1.5.0.20230420.dist-info/METADATA,sha256=U5xgWgF2gugpAdTH8wsYSqYDIjRZy_-LlWx9L8ZAD1M,19825
+sparsezoo_nightly-1.5.0.20230420.dist-info/NOTICE,sha256=naAyHz-LxMVCUVA27ssHBRIifnAixYvIhas5XTnEiO8,1414
+sparsezoo_nightly-1.5.0.20230420.dist-info/WHEEL,sha256=OqRkF0eY5GHssMorFjlbTIq072vpHpF60fIQA6lS9xA,92
+sparsezoo_nightly-1.5.0.20230420.dist-info/entry_points.txt,sha256=2tpzvrHBD--Om3jpHnfw1gx6EqA2IPFqnfJIl-RPX3o,217
+sparsezoo_nightly-1.5.0.20230420.dist-info/top_level.txt,sha256=SE5RMAyyIBKn6fDrXXF33MqdfB2Am0a9n9HRLAcrcZI,10
+sparsezoo_nightly-1.5.0.20230420.dist-info/RECORD,,
```

